{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Enrichment to Azure Cognitive Search\n",
    "\n",
    "In this Jupyter Notebook, we create and run enrichment steps to unlock searchable content in the specified Azure blob. It performs operations over mixed content in Azure Storage, such as images and application files, using a skillset that analyzes and extracts text information that becomes searchable in Azure Cognitive Search. \n",
    "The reference sample can be found at [Tutorial: Use Python and AI to generate searchable content from Azure blobs](https://docs.microsoft.com/azure/search/cognitive-search-tutorial-blob-python).\n",
    "\n",
    "Although only  PDF files are used here, this can be done at a much larger scale and Azure Cognitive Search supports a range of other file formats including: Microsoft Office (DOCX/DOC, XSLX/XLS, PPTX/PPT, MSG), HTML, XML, ZIP, and plain text files (including JSON).\n",
    "\n",
    "This notebook creates the following objects on your search service:\n",
    "\n",
    "+ search index\n",
    "+ data source\n",
    "+ skillset\n",
    "+ indexer\n",
    "\n",
    "In the last step, you'll run queries against the search index to explore the text output that was generated for each blob.\n",
    "\n",
    "This notebook calls the [Search REST APIs](https://docs.microsoft.com/rest/api/searchservice/), but you can also use the Azure.Search.Documents client library in the Azure SDK for Python to perform the same steps. See this [Python quickstart](https://docs.microsoft.com/azure/search/search-get-started-python) for details.\n",
    "\n",
    "To run this notebook, you should have already uploade the sample data to a blob container in Azure Storage account. Replace the placeholders for the search service endpoint, the admin API key, Azure Storage connection string, and blob container. Once you've provided all four values, you can run all cells, but the query won't return results until the indexer is finished and the search index is loaded. \n",
    "\n",
    "We recommend running each step and making sure it completes before moving on.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-tutorial-blob\n",
    "\n",
    "https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-AI-Enrichment/PythonTutorial-AzureSearch-AIEnrichment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Accounts and Keys\n",
    "\n",
    "api_version = '2021-04-30-Preview'\n",
    "\n",
    "# endpoint = os.environ.get(\"SEARCH_ENDPOINT\")\n",
    "# api_key = os.getenv(\"SEARCH_KEY\")\n",
    "# datasourceConnectionString = os.getenv(\"DATASOURCE_CONNECTION_STRING\")\n",
    "# cog_services_name = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_NAME\")\n",
    "# cog_services_key = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_KEY\")\n",
    "\n",
    "endpoint = \"https://azure-cog-search-pabdyosydd7ta.search.windows.net\"\n",
    "api_key = \"DDDUwtXOCSOjm1fPBRLNFofKEEvxXDpGF0Sy4S3ktjAzSeAgbz9Q\"\n",
    "datasourceConnectionString = \"DefaultEndpointsProtocol=https;AccountName=arxivdatasetcs;AccountKey=M0f/46RGw1IvIpSEXuR7hyprzwvVBiCvIbKYNIlbtJzD2X96KBegKZp59pg4soiu2hSjtRXfhl/5+AStsWkLPA==;EndpointSuffix=core.windows.net\"\n",
    "cog_services_name = \"cognitive-service-pabdyosydd7ta\"\n",
    "cog_services_key = \"54c7c95ed3a74e2da7694dbd995a093c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names for the data source, skillset, index and indexer\n",
    "datasource_name = \"cogsrch-datasource\"\n",
    "skillset_name = \"cogsrch-skillset\"\n",
    "index_name = \"cogsrch-index\"\n",
    "indexer_name = \"cogsrch-indexer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "api_version = '2021-04-30-Preview'\n",
    "headers = {'Content-Type': 'application/json','api-key': api_key}\n",
    "params = {'api-version': api_version}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Source (Blob container with the Arxiv CS pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a data source\n",
    "# This data source points to your Azure Storage account.\n",
    "# You should already have a blob container that contains the sample data\n",
    "\n",
    "datasource_payload = {\n",
    "    \"name\": datasource_name,\n",
    "    \"description\": \"Demo files to demonstrate cognitive search capabilities.\",\n",
    "    \"type\": \"azureblob\",\n",
    "    \"credentials\": {\n",
    "        \"connectionString\": datasourceConnectionString\n",
    "    },\n",
    "    \"container\": {\n",
    "        \"name\": \"pdf\"\n",
    "    }\n",
    "}\n",
    "r = requests.put(endpoint + \"/datasources/\" + datasource_name,\n",
    "                 data=json.dumps(datasource_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Skillset - OCR, Text Splitter, Language Detection, KeyPhrase extraction, Entity Recognition\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-working-with-skillsets\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset\n",
    "skillset_payload = {\n",
    "    \"name\": skillset_name,\n",
    "    \"description\": \"Extract entities, detect language and extract key-phrases\",\n",
    "    \"skills\":\n",
    "    [\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Vision.OcrSkill\",\n",
    "            \"description\": \"Extract text (plain and structured) from image.\",\n",
    "            \"context\": \"/document/normalized_images/*\",\n",
    "            \"defaultLanguageCode\": \"en\",\n",
    "            \"detectOrientation\": True,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"image\",\n",
    "                  \"source\": \"/document/normalized_images/*\"\n",
    "                }\n",
    "            ],\n",
    "                \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.MergeSkill\",\n",
    "            \"description\": \"Create merged_text, which includes all the textual representation of each image inserted at the right location in the content field. This is useful for PDF and other file formats that supported embedded images.\",\n",
    "            \"context\": \"/document\",\n",
    "            \"insertPreTag\": \" \",\n",
    "            \"insertPostTag\": \" \",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\":\"text\", \"source\": \"/document/content\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"itemsToInsert\", \"source\": \"/document/normalized_images/*/text\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\":\"offsets\", \"source\": \"/document/normalized_images/*/contentOffset\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"mergedText\", \n",
    "                  \"targetName\" : \"merged_text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"textSplitMode\": \"pages\",\n",
    "            \"maximumPageLength\": 4000,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\",\n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"textItems\",\n",
    "                    \"targetName\": \"pages\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.LanguageDetectionSkill\",\n",
    "            \"description\": \"If you have multilingual content, adding a language code is useful for filtering\",\n",
    "            \"context\": \"/document\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\",\n",
    "                  \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"languageName\",\n",
    "                  \"targetName\": \"language\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.KeyPhraseExtractionSkill\",\n",
    "            \"context\": \"/document/pages/*\",\n",
    "            \"maxKeyPhraseCount\": 2,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/pages/*\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"keyPhrases\",\n",
    "                    \"targetName\": \"keyPhrases\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.V3.EntityRecognitionSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"categories\": [\"Person\", \"Location\", \"Organization\", \"DateTime\", \"URL\", \"Email\"],\n",
    "            \"minimumPrecision\": 0.3, \n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"persons\", \n",
    "                    \"targetName\": \"persons\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"locations\", \n",
    "                    \"targetName\": \"locations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"organizations\", \n",
    "                    \"targetName\": \"organizations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"dateTimes\", \n",
    "                    \"targetName\": \"dateTimes\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"urls\", \n",
    "                    \"targetName\": \"urls\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"emails\", \n",
    "                    \"targetName\": \"emails\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"cognitiveServices\": {\n",
    "        \"@odata.type\": \"#Microsoft.Azure.Search.CognitiveServicesByKey\",\n",
    "        \"description\": cog_services_name,\n",
    "        \"key\": cog_services_key\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/skillsets/\" + skillset_name,\n",
    "                 data=json.dumps(skillset_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the request defines the schema of the search index. A fields collection requires one field to be designated as the key. For blob content, this field is often the \"metadata_storage_path\" that uniquely identifies each blob in the container.\n",
    "\n",
    "In this schema, the \"text\" field receives OCR output, \"content\" receives merged output, \"language\" receives language detection output. Key phrases, entities, and several fields lifted from blob storage comprise the remaining entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "# Queries operate over the searchable fields and filterable fields in the index\n",
    "index_payload = {\n",
    "    \"name\": index_name,\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"text\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"language\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"true\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"keyPhrases\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"persons\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"locations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"organizations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dateTimes\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"urls\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"emails\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_path\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": \"true\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_name\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "            }\n",
    "    ],\n",
    "    \"semantic\": {\n",
    "      \"configurations\": [\n",
    "        {\n",
    "          \"name\": \"my-semantic-config\",\n",
    "          \"prioritizedFields\": {\n",
    "            \"prioritizedContentFields\": [\n",
    "                {\n",
    "                    \"fieldName\": \"content\"\n",
    "                }\n",
    "                ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexes/\" + index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run the Indexer - (runs the pipeline)\n",
    "This process takes about 30 mins to load all the Arxiv CS pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Create Indexer to drive the pipeline. The three components you have created thus far (data source, skillset, index) are inputs to an indexer. Creating the indexer on Azure Cognitive Search is the event that puts the entire pipeline into motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer\n",
    "indexer_payload = {\n",
    "    \"name\": indexer_name,\n",
    "    \"dataSourceName\": datasource_name,\n",
    "    \"targetIndexName\": index_name,\n",
    "    \"skillsetName\": skillset_name,\n",
    "    \"fieldMappings\": [\n",
    "        {\n",
    "          \"sourceFieldName\" : \"metadata_storage_path\",\n",
    "          \"targetFieldName\" : \"metadata_storage_path\",\n",
    "          \"mappingFunction\" : { \"name\" : \"base64Encode\" }\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"metadata_storage_name\",\n",
    "            \"targetFieldName\": \"metadata_storage_name\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputFieldMappings\":\n",
    "    [\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/merged_text\",\n",
    "            \"targetFieldName\": \"content\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\" : \"/document/normalized_images/*/text\",\n",
    "            \"targetFieldName\" : \"text\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/language\",\n",
    "            \"targetFieldName\": \"language\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/pages/*/keyPhrases/*\",\n",
    "            \"targetFieldName\": \"keyPhrases\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/persons\", \n",
    "          \"targetFieldName\" : \"persons\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/locations\", \n",
    "          \"targetFieldName\" : \"locations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/organizations\",\n",
    "            \"targetFieldName\": \"organizations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/dateTimes\",\n",
    "            \"targetFieldName\": \"dateTimes\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/urls\",\n",
    "            \"targetFieldName\": \"urls\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/emails\",\n",
    "            \"targetFieldName\": \"emails\"\n",
    "        }\n",
    "    ],\n",
    "    \"parameters\":\n",
    "    {\n",
    "        \"maxFailedItems\": -1,\n",
    "        \"maxFailedItemsPerBatch\": -1,\n",
    "        \"configuration\":\n",
    "        {\n",
    "            \"dataToExtract\": \"contentAndMetadata\",\n",
    "            \"imageAction\": \"generateNormalizedImages\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexers/\" + indexer_name,\n",
    "                 data=json.dumps(indexer_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Status: success\n",
      "Items Processed: 9887\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Optionally, get indexer status to confirm that it's running\n",
    "r = requests.get(endpoint + \"/indexers/\" + indexer_name +\n",
    "                 \"/status\", headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))\n",
    "print(r.status_code)\n",
    "print(\"Status:\",r.json().get('lastResult').get('status'))\n",
    "print(\"Items Processed:\",r.json().get('lastResult').get('itemsProcessed'))\n",
    "print(r.ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the service for the index definition\n",
    "# Query responses can be verbose. If you get \"Output exceeds the size limit. Open the full output data in a text editor\", open the output in an editor.\n",
    "# r = requests.get(endpoint + \"/indexes/\" + index_name,\n",
    "#                  headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the index to return the contents of \"organizations\", created through Entity Recognition during enrichment\n",
    "# For keyword search, replace the asterisk with comma-separated query terms: search=microsoft,azure\n",
    "# r = requests.get(endpoint + \"/indexes/\" + index_name +\n",
    "#                  \"/docs?&search=*&$select=organizations\", headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-pabdyosydd7ta.search.windows.net/indexes/cogsrch-index/docs?api-version=2021-04-30-Preview&search=what is artficial inteligence&select=content&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-true&highlightPreTag=%3Cspan%20style%3D%22background-color%3A%20%23f5e8a3%22%3E&highlightPostTag=%3C%2Fspan%3E\n",
      "200\n",
      "Results Found: 9795, Results Returned: 5\n",
      "Highest Search Score: 24.213554\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "url = endpoint + '/indexes/'+ index_name + '/docs'\n",
    "url += '?api-version={}'.format(api_version)\n",
    "url += '&search=what is artficial inteligence'\n",
    "url += '&select=content'\n",
    "url += '&$top=5'\n",
    "url += '&queryLanguage=en-us'\n",
    "url += '&queryType=semantic'\n",
    "url += '&semanticConfiguration=my-semantic-config'\n",
    "url += '&$count=true'\n",
    "url += '&speller=lexicon'\n",
    "url += '&answers=extractive|count-3'\n",
    "url += '&captions=extractive|highlight-true'\n",
    "url += '&highlightPreTag=' + urllib.parse.quote('<span style=\"background-color: #f5e8a3\">', safe='')\n",
    "url += '&highlightPostTag=' + urllib.parse.quote('</span>', safe='')\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "print(url)\n",
    "print(resp.status_code)\n",
    "\n",
    "search_results = resp.json()\n",
    "print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))\n",
    "print(\"Highest Search Score: {}\".format(search_results['value'][0]['@search.score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i= 0\n",
    "# for r in search_results.items():\n",
    "#     pprint(r)\n",
    "#     i+=1\n",
    "#     if i==4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Top Answers</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.8466796875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The  main purpose of artificial intelligence is find a way of organizing knowledge in such a  way that helps decision making to take place rapidly and efficiently; which means that  learning should happen at optimal speed and in compact storage."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.82421875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "AIXI is a universal theory without adjustable parame- ters, making no assumptions about the environment except that it is sampled from a computable distribution. From an algorithmic complexity perspective, the AIXI model generalizes optimal passive universal induction to the case of active agents."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Top Results</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0607138v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.202789306640625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The  main purpose of artificial intelligence is find a way of organizing knowledge in such a  way that helps decision making to take place rapidly and efficiently; which means that  learning should happen at optimal speed and in compact storage."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0311031v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.036285400390625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The artificial intelligence capabilities of the SP model are  reviewed and its relationship with other artificial intelligence systems is  described. Also considered are ways in which current prototypes may be  translated into an ‘industrial strength’ working system."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0605024v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.7305145263671875</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "– D. Wechsler  • “Intelligence is a very general mental ca- pability that, among other things, involves the ability to reason, plan, solve problems,  think abstractly, comprehend complex ideas, learn quickly and learn from experience.”"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0603102v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.4029693603515625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Most notably the  Distributed Artificial Intelligence (DAI) applications  that are suitable for logic programming can profit  from the use of the protocol. After proving its  usefulness, we went further, developing a new  version of the protocol, making it more reliable and  extending its functionality."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0212030v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.211517333984375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The learning task is to construct a function  from  to , where  is the space of the predictor attributes and  is the  space of the attribute that is to be predicted."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers from semantic Search\n",
    "display(HTML('<h3>Top Answers</h3>'))\n",
    "for result in search_results['@search.answers']:\n",
    "    if result['score'] > 0.5:\n",
    "        display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "        display(HTML(result['text']))\n",
    "\n",
    "# Results from semantic search\n",
    "\n",
    "contents = dict()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h3>Top Results</h3>'))\n",
    "for result in search_results['value']:\n",
    "    if result['@search.rerankerScore'] > 1:\n",
    "        display(HTML('<h5>' + result['metadata_storage_name'] + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: ' + str(result['@search.rerankerScore']) + '</h5>'))\n",
    "        for caption in result['@search.captions']:\n",
    "            # print(caption)\n",
    "            display(HTML(caption['text']))\n",
    "        contents[result['metadata_storage_name']]=result['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we want OpenAI to give a better answer chat style, so we instead of sending this results, we send the content of this articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the 4096 tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "This is what the APP will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 1\\n\\nTheoretical Analyses of Cross-Validation Error and\\n\\nVoting in Instance-Based Learning\\n\\nPeter Turney\\nKnowledge Systems Laboratory\\n\\nInstitute for Information Technology\\nNational Research Council Canada\\n\\nOttawa, Ontario, Canada\\nK1A 0R6\\n\\n613-993-8564\\npeter@ai.iit.nrc.ca\\n\\nRunning Head: Error and Voting\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 2\\n\\nTheoretical Analyses of Cross-Validation Error and\\n\\nVoting in Instance-Based Learning\\n\\nAbstract\\n\\nThis paper begins with a general theory of error in cross-validation testing of algorithms\\n\\nfor supervised learning from examples. It is assumed that the examples are described by\\n\\nattribute-value pairs, where the values are symbolic. Cross-validation requires a set of\\n\\ntraining examples and a set of testing examples. The value of the attribute that is to be\\n\\npredicted is known to the learner in the training set, but unknown in the testing set. The\\n\\ntheory demonstrates that cross-validation error has two components: error on the training\\n\\nset (inaccuracy) and sensitivity to noise (instability).\\n\\nThis general theory is then applied to voting in instance-based learning. Given an\\n\\nexample in the testing set, a typical instance-based learning algorithm predicts the desig-\\n\\nnated attribute by voting among the k nearest neighbors (the k most similar examples) to\\n\\nthe testing example in the training set. Voting is intended to increase the stability (resis-\\n\\ntance to noise) of instance-based learning, but a theoretical analysis shows that there are\\n\\ncircumstances in which voting can be destabilizing. The theory suggests ways to minimize\\n\\ncross-validation error, by insuring that voting is stable and does not adversely affect\\n\\naccuracy.\\n\\n1  Introduction\\nThis paper is concerned with cross-validation testing of algorithms for supervised learning\\n\\nfrom examples. It is assumed that the examples are described by attribute-value pairs,\\n\\nwhere the attributes can have a finite number of symbolic values. The learning task is to\\n\\npredict the value of one of the attributes, given the value of the remaining attributes. It is\\n\\nassumed that each example is described by the same set of attributes.\\n\\nWithout loss of generality, we may assume that the attributes are restricted to boolean\\n\\nvalues. Let us suppose that each example has  attributes. We may think of an example\\n\\nas a boolean vector in the space . The learning task is to construct a function\\n\\nfrom  to , where  is the space of the predictor attributes and  is the\\n\\nspace of the attribute that is to be predicted.\\n\\nCross-validation testing requires a set of training examples and a set of testing\\n\\nr 1+\\n\\n0 1{ , }r 1+\\n\\n0 1{ , }r 0 1{ , } 0 1{ , }r 0 1{ , }\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 3\\n\\nexamples. The learning algorithm (the student) is scored by a teacher, according to the\\n\\nstudent’s performance on the testing set. The teacher knows the values of all of the\\n\\nattributes of all of the examples in the training set and the testing set. The student knows\\n\\nall of the values in the training set, but the student does not know the values of the attribute\\n\\nthat is to be predicted in the testing set. The student uses the training set to develop a\\n\\nmodel of the data. The student then uses the model to make predictions for the testing set.\\n\\nThe teacher compares the student’s predictions with the actual values in the testing set. A\\n\\nmismatch between the student’s prediction and the actual value is counted as an error. The\\n\\nstudent’s goal is to minimize the number of errors that it makes on the testing set.\\n\\nIn a recent paper (Turney, 1993), a general theory of error in cross-validation testing of\\n\\nalgorithms for predicting real-valued attributes is presented. 1 Section 2 of this paper\\n\\nextends the theory of Turney (1993) to algorithms for predicting boolean-valued\\n\\nattributes. This section shows that cross-validation error has two components: error on the\\n\\ntraining set and sensitivity to noise. Error on the training set is commonly used as a\\n\\nmeasure of accuracy (Fraser, 1976). Turney (1990) introduces a formal definition of\\n\\nstability as a measure of the sensitivity of algorithms to noise. Section 2 proves that cross-\\n\\nvalidation error is bounded by the sum of the training set error and the instability. The\\n\\noptimal cross-validation error is established, and it is proven that the strategy of minimiz-\\n\\ning error on the training set (maximizing accuracy) is sub-optimal.\\n\\nSection 3 examines the cross-validation error of a simple form of instance-based\\n\\nlearning (Aha et al., 1991; Kibler et al., 1989). Instance-based learning is not a single\\n\\nlearning algorithm; it is a paradigm for a class of learning algorithms. It is related to the\\n\\nnearest neighbor pattern classification paradigm (Dasarathy, 1991). In instance-based\\n\\nlearning, the student’s model of the data consists of simply storing the training set. Given\\n\\nan example from the testing set, the student makes a prediction by looking for similar\\n\\nexamples in the training set. Section 3 proves that this simple form of instance-based\\n\\nlearning produces sub-optimal cross-validation error.\\n\\nLooking for the single most similar example is sub-optimal because it is overly\\n\\nsensitive to noise in the data. Section 4 deals with instance-based learning algorithms that\\n\\nlook for the k most similar examples, where . In general, the k most similar examples\\n\\nwill not all agree on the value of the attribute that is to be predicted. This section examines\\n\\nalgorithms that resolve this conflict by voting (Dasarathy, 1991). For example, suppose\\n\\n and the value of the attribute that is to be predicted is 1 for two of the three\\n\\nexamples and 0 for the remaining example. If the algorithm uses majority voting, then the\\n\\nprediction is that the value is 1.\\n\\nk 1≥\\n\\nk 3=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 4\\n\\nSection 4 presents a detailed theoretical analysis of voting in instance-based learning.\\n\\nOne motivation for voting is the desire to make instance-based learning more stable (more\\n\\nresistant to noise in the data). This section examines the stability of voting in the best case,\\n\\nthe worst case, and the average case. It is shown that, in the worst case, voting can be\\n\\ndestabilizing. That is, in certain circumstances, voting can actually increase the sensitivity\\n\\nto noise.\\n\\nSection 5 discusses the practical application of this theory. It is shown how it is\\n\\npossible to estimate the expected cross-validation error from the training set. This section\\n\\npresents estimators that can indicate whether voting will increase or decrease stability for\\n\\na particular set of data. This gives a method for choosing the value of k that will minimize\\n\\nthe cross-validation error.\\n\\nSection 6 compares the work presented here with related work. The most closely\\n\\nrelated work is Turney (1993), which first introduced many of the concepts used here.\\n\\nThere are interesting differences, which arise because Turney (1993) involves real-valued\\n\\nattributes and classes, while this paper involves boolean-valued attributes and classes.\\n\\nThis theory is closely related to Akaike Information Criterion statistics (Sakamoto et al.,\\n\\n1986), as is discussed elsewhere (Turney, 1993). There is also an interesting connection\\n\\nwith some prior work in nearest neighbor pattern classification (Cover & Hart, 1967).\\n\\nFinally, Section 7 considers future work. One weakness of this general theory of cross-\\n\\nvalidation error is that it does not model interpolation and extrapolation. Another area for\\n\\nfuture research is applying the theory to problems other than voting in instance-based\\n\\nlearning.\\n\\n2  Cross-Validation Error\\nThis section presents a general theory of error in cross-validation testing of algorithms for\\n\\npredicting symbolic attributes. In order to make the exposition simpler, the discussion is\\n\\nrestricted to boolean-valued attributes. It is not difficult to extend the results presented\\n\\nhere to n-valued attributes, where n is any integer larger than one.\\n\\n2.1  Exclusive-Or\\n\\nThis paper makes extensive use of the boolean exclusive-or operator. Suppose x and y are\\n\\nboolean variables. That is, x and y range over the set . We may write  for “x\\n\\nexclusive-or y”. The expression  has the value 1 if and only if exactly one of x and y\\n\\nhas the value 1. Here are some of the properties of exclusive-or:\\n\\n0 1{ , } x y⊕\\n\\nx y⊕\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 5\\n\\n(1)\\n\\n(2)\\n\\n(3)\\n\\n(4)\\n\\n(5)\\n\\n(6)\\n\\nThese properties can easily be verified with a truth-table.\\n\\nThe following results use exclusive-or with boolean vectors. Suppose  and  are\\n\\nboolean vectors in the space . The expression  represents the vector that\\n\\nresults from applying exclusive-or to corresponding elements of  and :\\n\\n(7)\\n\\n(8)\\n\\n(9)\\n\\n(10)\\n\\n2.2  Accuracy and Stability\\n\\nSuppose we have a black box with r inputs and one output, where the inputs and the output\\n\\ncan be represented by boolean values. Let the boolean vector  represent the inputs to the\\n\\nblack box:\\n\\n(11)\\n\\nLet y represent the output of the black box. Suppose that the black box has a deterministic\\n\\ncomponent f and a random component z. The deterministic component f is a function that\\n\\nmaps from  to . The random component z is a random boolean variable. The\\n\\nprobability that z is 1 is p. The probability that z is 0 is . The black box is represented\\n\\nby the equation:\\n\\n(12)\\n\\nThe variable p is a probability in the range .\\n\\nx 0⊕ x=\\nx 1⊕ x¬=\\n\\nx y⊕ y x⊕=\\nx x⊕ 0=\\n\\nx x¬⊕ 1=\\nx y z⊕( )⊕ x y⊕( ) z⊕=\\n\\nx y\\n\\n0 1{ , }n x y⊕\\n\\nx y\\n\\nz x y⊕=\\n\\nx x1 … xn=\\n\\ny y1 … yn=\\n\\nz x1 y1⊕ … xn yn⊕=\\n\\nv\\n\\nv x1 … xr=\\n\\n0 1{ , }r 0 1{ , }\\n\\n1 p−\\n\\ny f v( ) z⊕=\\n\\n0 1[ , ]\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 6\\n\\nIf p is close to 0, then z is usually 0, so the deterministic component dominates and the\\n\\noutput y is usually  (see equation (1) above). If p is close to 1, then z is usually 1, so the\\n\\noutput is usually  (see (2)). We may think of p as the probability that  will be\\n\\nrandomly negated. If p is 0.5, then the random component z completely hides the deter-\\n\\nministic component f. When p is between 0.5 and 1.0,  will be negated more often than\\n\\nnot. When we know that p is greater than 0.5, we can negate the output of the black box:\\n\\n(13)\\n\\nThis counteracts the expected negation of  by the random component z. In (12) the\\n\\noutput y is  with probability . In (13) the output y is  with probability p.\\n\\nSuppose we perform a series of n experiments with the black box. We may represent\\n\\nthe inputs in the n experiments with a matrix X:\\n\\n(14)\\n\\nLet the i-th row of the matrix X be represented by the vector , where:\\n\\n(15)\\n\\nThe vector  contains the values of the r inputs for the i-th experiment. Let the j-th\\n\\ncolumn of the matrix X be represented by the vector , where:\\n\\n(16)\\n\\nThe vector  contains the values of the j-th input for the n experiments. Let the n outputs\\n\\nbe represented by the vector , where:\\n\\nf v( )\\n\\nf v( )¬ f v( )\\n\\nf v( )\\n\\ny f v( ) z⊕( )¬=\\n\\nf v( )\\n\\nf v( ) 1 p− f v( )\\n\\nX\\n\\nx1 1, … x1 r,\\n… xi j, …\\n\\nxn 1, … xn r,\\n\\n=\\n\\nvi\\n\\nvi xi 1, … xi r,= i 1 …, n,=\\n\\nvi\\n\\nxj\\n\\nxj\\n\\nx1 j,\\n…\\nxn j,\\n\\n= j 1 …, r,=\\n\\nxj\\n\\ny\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 7\\n\\n(17)\\n\\nThe scalar  is the output of the black box for the i-th experiment.\\n\\nThe function f can be extended to a vector function , where:\\n\\n(18)\\n\\nOur model for the n experiments is:\\n\\n(19)\\n\\nThe vector  is a sequence of n independent random boolean variables, each having the\\n\\nvalue 1 with probability p:\\n\\n(20)\\n\\nLet us suppose that we are trying to develop a model of f. We may write  to\\n\\nrepresent the model’s prediction for , given that the model is based on the data X and\\n\\n. We can extend  to a vector function:\\n\\n(21)\\n\\nThus  represents the model’s prediction for , given the data X and .\\n\\nSuppose we repeat the whole sequence of n experiments, holding the inputs X\\n\\nconstant:\\n\\ny\\ny1\\n\\n…\\nyn\\n\\n=\\n\\nyi\\n\\nf X( )\\n\\nf X( )\\nf v1( )\\n…\\n\\nf vn( )\\n=\\n\\ny f X( ) z⊕=\\n\\nz\\n\\nz\\nz1\\n\\n…\\nzn\\n\\n=\\n\\nm v X y,( )\\n\\nf v( )\\n\\ny m v X y,( )\\n\\nm X X y,( )\\nm v1 X y,( )\\n\\n…\\nm vn X y,( )\\n\\n=\\n\\nm X X y,( ) f X( ) y\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 8\\n\\n(22)\\n\\n(23)\\n\\nThe outputs of the first set of n experiments are represented by  and the outputs of the\\n\\nsecond set of n experiments are represented by :\\n\\n(24)\\n\\nAlthough the inputs X are the same, the outputs may have changed, due to the random\\n\\ncomponent. That is, assuming p is neither 0 nor 1, it is possible that :\\n\\n(25)\\n\\nLet the data  be the training set and let the data  be the testing set in cross-\\n\\nvalidation testing of the model m. The cross-validation error vector  is:\\n\\n(26)\\n\\n(27)\\n\\n is 1 if and only if the prediction of the model  differs from the output\\n\\nin the testing data. We may write  for the length of the cross-validation error vector:\\n\\n(28)\\n\\nIn other words,  is the number of errors that the model  makes on the\\n\\ntesting set.\\n\\ny1 f X( ) z1⊕=\\n\\ny2 f X( ) z2⊕=\\n\\ny1\\n\\ny2\\n\\ny1\\n\\ny1 1,\\n…\\n\\ny1 n,\\n\\n= y2\\n\\ny2 1,\\n…\\n\\ny2 n,\\n\\n=\\n\\nz1 z2≠\\n\\nz1\\n\\nz1 1,\\n…\\n\\nz1 n,\\n\\n= z2\\n\\nz2 1,\\n…\\n\\nz2 n,\\n\\n=\\n\\nX y1( , ) X y2( , )\\n\\nec\\n\\nec m X X y1,( ) y2⊕=\\n\\nec\\n\\nec 1,\\n…\\n\\nec n,\\n\\nm v1 X y1,( ) y2 1,⊕\\n…\\n\\nm vn X y1,( ) y2 n,⊕\\n= =\\n\\nec i, m vi X y1,( ) y2 i,\\n\\nec\\n\\nec ec i,\\ni 1=\\n\\nn\\n\\n∑=\\n\\nec m X X y1,( )\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 9\\n\\nThe model  has been tuned to perform well on the training set .\\n\\nTherefore the number of errors made on the training set may be deceptively low. To get a\\n\\ngood indication of the quality of the model, we must test it on an independent set of data.\\n\\nSome authors call this error measure “cross-validation error”, while other authors call it\\n\\n“train-and-test error” (Weiss and Kulikowski, 1991). In this paper, the former terminology\\n\\nis used. 2\\n\\nIt is assumed that our goal is to minimize the expected number of errors  that\\n\\nthe model makes on the testing set.  is the expectation operator from probability\\n\\ntheory (Fraser, 1976). If  is a function of a random variable x, where  (  is the set\\n\\nof possible values of x) and the probability of observing a particular value of x is ,\\n\\nthen  is:\\n\\n(29)\\n\\nThe expected cross-validation error  depends on the random boolean vectors\\n\\nand .\\n\\nThe next theorem gives some justification for the assumption that X is the same in the\\n\\ntraining set  and the testing set .\\n\\nTheorem 1: Let D be an arbitrary probability distribution on . Let the n rows\\n\\n of X be independently randomly selected according to the distribution D. Let the\\n\\nvector  be randomly selected according to the distribution D. Let  be the probability\\n\\nthat  is not equal to any of . Then:\\n\\n(30)\\n\\nProof: Let  be the probability of randomly selecting  with the distribution D. The\\n\\nprobability that  is not equal to any of  is thus:\\n\\n(31)\\n\\nThe expected value of  is:\\n\\nm v X y1,( ) X y1( , )\\n\\nE ec( )\\n\\nE …( )\\n\\nt x( ) x S∈ S\\n\\np x( )\\n\\nE t x( )( )\\n\\nE t x( )( ) t x( )p x( )\\nx S∈\\n∑=\\n\\nE ec( ) z1\\n\\nz2\\n\\nX y1( , ) X y2( , )\\n\\n0 1{ , }r\\n\\nv1 … vn, ,\\n\\nv p*\\n\\nv v1 … vn, ,\\n\\nE p*( ) 1 2 r−−( ) n≤\\n\\nD v( ) v\\n\\nv v1 … vn, ,\\n\\np* 1 D v( )−( ) n=\\n\\np*\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 10\\n\\n(32)\\n\\n(33)\\n\\nThe expected value is at its maximum when D is the uniform distribution on . For\\n\\nthe uniform distribution, . Therefore:\\n\\n(34)\\n\\n(35)\\n\\n(36)\\n\\nThe implication of Theorem 1 is that, as n increases, the probability that the inputs in the\\n\\ntraining set and the testing set are the same approaches 1. Thus the assumption that X is the\\n\\nsame in the training set and the testing set is reasonable for large values of n.\\n\\nAlthough it is assumed that the inputs are boolean, only Theorem 1 uses this assump-\\n\\ntion; none of the following results depend on the assumption that the inputs are boolean.\\n\\nThe inputs could just as well be real numbers, so that f maps from  to . However,\\n\\nit is necessary to assume that the output is boolean. If the output is real-valued, then we\\n\\nmay turn to the analysis in Turney (1993).\\n\\nCover and Hart (1967) prove the following Lemma (their symbols have been changed\\n\\nto be consistent with the notation used here):\\n\\nLemma 1: Let  and  be independent identically distributed random variables\\n\\ntaking values in a separable metric space S, with metric d. Let  be the nearest neighbor,\\n\\naccording to the metric d, to  in the set . Then, as n approaches infinity,\\n\\napproaches 0, with probability 1.\\n\\nProof: See Cover and Hart (1967)\\n\\nCover and Hart (1967) assume that n is large and the probability distribution for\\n\\n is a continuous function of . It follows from Lemma 1 that, as n\\n\\nE p*( ) p* D v( )\\nv 0 1{ , }r∈\\n\\n∑=\\n\\n1 D v( )−( ) nD v( )\\nv 0 1{ , }r∈\\n\\n∑=\\n\\n0 1{ , }r\\n\\nD v( ) 2 r−=\\n\\nE p*( ) 1 2 r−−( ) n\\n2 r−\\n\\nv 0 1{ , }r∈\\n∑≤\\n\\n2r 1 2 r−−( ) n\\n2 r−=\\n\\n1 2 r−−( ) n=\\n\\n.\\n\\nℜr 0 1{ , }\\n\\nv v1 … vn, ,\\n\\nvi\\n\\nv v1 … vn, , d v vi,( )\\n\\n.\\n\\nP f v( ) z⊕ 1=( ) v\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 11\\n\\napproaches infinity,  approaches . This is similar to\\n\\nTheorem 1 here, except that S is continuous. Note that, if the probability distribution for\\n\\n is a continuous function of , then z must be a function of , , in order\\n\\nto compensate for the fact that  is discontinuous. Thus the assumption that the distribu-\\n\\ntion is continuous is relatively strong.\\n\\nFor the rest of this paper, let us assume that f maps from  to . We may\\n\\nassume that X is the same in the training set and the testing set. This assumption may be\\n\\njustified with Theorem 1. Alternatively, we could assume that f maps from  to\\n\\nand use Lemma 1 to justify the assumption that X is the same in the training set and the\\n\\ntesting set. However, the analysis is simpler when z is not a function of .\\n\\nThe error on the training set  is:\\n\\n(37)\\n\\n(38)\\n\\n is 1 if and only if the prediction of the model  differs from the output\\n\\nin the training data.\\n\\nThere is another form of error that is of interest. We may call this error instability:\\n\\n(39)\\n\\n(40)\\n\\nInstability is a measure of the sensitivity of the model to noise in the data. If the model\\n\\nresists noise, then  will be relatively similar to , so  will be\\n\\nrelatively small. If the model is sensitive to noise, then  will be relatively dis-\\n\\nsimilar from , so  will be relatively large.\\n\\nP f v( ) z⊕ 1=( ) P f vi( ) z⊕ 1=( )\\n\\nP f v( ) z⊕ 1=( ) v v z v( )\\n\\nf v( )\\n\\n0 1{ , }r 0 1{ , }\\n\\nℜr 0 1{ , }\\n\\nv\\n\\net\\n\\net m X X y1,( ) y1⊕=\\n\\net\\n\\net 1,\\n…\\net n,\\n\\nm v1 X y1,( ) y1 1,⊕\\n…\\n\\nm vn X y1,( ) y1 n,⊕\\n= =\\n\\net i, m vi X y1,( ) y1 i,\\n\\nes m X X y1,( ) m X X y2,( )⊕=\\n\\nes\\n\\nes 1,\\n…\\n\\nes n,\\n\\nm v1 X y1,( ) m v1 X y2,( )⊕\\n…\\n\\nm vn X y1,( ) m vn X y2,( )⊕\\n= =\\n\\nm X X y1,( ) m X X y2,( ) E es( )\\n\\nm X X y1,( )\\n\\nm X X y2,( ) E es( )\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 12\\n\\nThe following theorem shows the relationship between cross-validation error, error on\\n\\nthe training set, and instability.\\n\\nTheorem 2: The expected cross-validation error is less than or equal to the sum of the\\n\\nexpected error on the training set and the expected instability:\\n\\n(41)\\n\\nProof: Let us introduce a new term :\\n\\n(42)\\n\\nDue to the symmetry of the training set (22) and the testing set (23), we have (from (26)\\n\\nand (42)):\\n\\n(43)\\n\\nRecall the definition of  (37):\\n\\n(44)\\n\\nIt follows from this definition that  differs from  in  locations. Recall the\\n\\ndefinition of  (39):\\n\\n(45)\\n\\nIt follows from this definition that  differs from  in  locations.\\n\\nTherefore  differs from  in at most  locations. Thus:\\n\\n(46)\\n\\nFinally:\\n\\n(47)\\n\\nThe next theorem is a variation on Theorem 2.\\n\\nTheorem 3: If  and  are statistically independent, then:\\n\\n(48)\\n\\nProof: Assume that  and  are statistically independent. Let us introduce a new term\\n\\nE ec( ) E et( ) E es( )+≤\\n\\neω\\n\\neω m X X y2,( ) y1⊕=\\n\\nE ec( ) E eω( )=\\n\\net\\n\\net m X X y1,( ) y1⊕=\\n\\ny1 m X X y1,( ) et\\n\\nes\\n\\nes m X X y1,( ) m X X y2,( )⊕=\\n\\nm X X y1,( ) m X X y2,( ) es\\n\\ny1 m X X y2,( ) et es+\\n\\neω et es+≤\\n\\nE ec( ) E eω( ) E et es+( )≤ E et( ) E es( )+= =\\n\\n.\\n\\net es\\n\\nE ec( ) E et( ) E es( ) 2\\nn\\n\\nE et( )E es( )−+=\\n\\net es\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 13\\n\\n:\\n\\n(49)\\n\\nWe see that:\\n\\n(50)\\n\\nRecall the definition of  (37):\\n\\n(51)\\n\\nRecall the definition of  (39):\\n\\n(52)\\n\\nWe have:\\n\\n(53)\\n\\n(54)\\n\\n(55)\\n\\n(56)\\n\\nLet us introduce the following terms:\\n\\n(57)\\n\\n(58)\\n\\n(59)\\n\\nSince  and  are statistically independent and , we have:\\n\\n(60)\\n\\nTherefore:\\n\\n(61)\\n\\n(62)\\n\\n(63)\\n\\n(64)\\n\\neω\\n\\neω m X X y2,( ) y1⊕=\\n\\nE ec( ) E eω( )=\\n\\net\\n\\net m X X y1,( ) y1⊕=\\n\\nes\\n\\nes m X X y1,( ) m X X y2,( )⊕=\\n\\net es⊕ m X X y1,( ) y1⊕( ) m X X y1,( ) m X X y2,( )⊕( )⊕=\\n\\nm X X y1,( ) m X X y1,( )⊕( ) y1 m X X y2,( )⊕( )⊕=\\n\\ny1 m X X y2,( )⊕=\\n\\neω=\\n\\npt E et( ) n⁄=\\n\\nps E es( ) n⁄=\\n\\npω E eω( ) n⁄=\\n\\net es eω et es⊕=\\n\\npω pt 1 ps−( ) ps 1 pt−( )+ pt ps 2ptps−+= =\\n\\nE ec( ) E eω( )=\\n\\nnpω=\\n\\nn pt ps 2ptps−+( )=\\n\\nE et( ) E es( ) 2\\nn\\n\\nE et( )E es( )−+=\\n\\n.\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 14\\n\\nThe assumptions of Theorem 3 are stronger than the assumptions of Theorem 2, but\\n\\nTheorem 3 gives a closer relationship between , , and .\\n\\nThe next theorem shows the optimal expected cross-validation error.\\n\\nTheorem 4: Suppose that f and p are known to the modeler. To minimize the expected\\n\\ncross-validation error, the modeler should set the model as follows:\\n\\n(65)\\n\\nWith this model, we have:\\n\\n(66)\\n\\n(67)\\n\\nProof: Suppose that . By (4), (39), and (65):\\n\\n(68)\\n\\nThus the model is perfectly stable. This is natural, since the model is not based on the data;\\n\\nit is based on the a priori knowledge of f. Consider the cross-validation error:\\n\\n(69)\\n\\n(70)\\n\\n(71)\\n\\n(72)\\n\\nThus:\\n\\n(73)\\n\\nConsider the error on the training set:\\n\\n(74)\\n\\nTherefore:\\n\\n(75)\\n\\nE ec( ) E et( ) E es( )\\n\\nm X X yi,( ) f X( ) if p 0.5≤\\n\\nf X( )¬ if p 0.5>\\n=\\n\\nE es( ) 0=\\n\\nE ec( ) E et( ) np if p 0.5≤\\nn 1 p−( ) if p 0.5>\\n\\n= =\\n\\np 0.5≤\\n\\nE es( ) E f X( ) f X( )⊕( ) 0= =\\n\\nec f X( ) y2⊕=\\n\\nf X( ) f X( ) z2⊕( )⊕=\\n\\nf X( ) f X( )⊕( ) z2⊕=\\n\\nz2=\\n\\nE ec( ) E z2( ) E z2 i,\\ni 1=\\n\\nn\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 E z2 i,( )\\n\\ni 1=\\n\\nn\\n\\n∑ p\\ni 1=\\n\\nn\\n\\n∑ np= = = = =\\n\\net f X( ) y1⊕ z1= =\\n\\nE et( ) E z1( ) E z2( ) E ec( ) np= = = =\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 15\\n\\nNow, suppose that . For instability, we have:\\n\\n(76)\\n\\nConsider the cross-validation error:\\n\\n(77)\\n\\n(78)\\n\\n(79)\\n\\n(80)\\n\\nThus:\\n\\n(81)\\n\\nConsider the error on the training set:\\n\\n(82)\\n\\nTherefore:\\n\\n(83)\\n\\nIt is clear that no model can have a lower  than this model, since  cannot be\\n\\npredicted\\n\\nThe next theorem considers models that minimize the error on the training set.\\n\\nTheorem 5: Let our model be as follows:\\n\\n(84)\\n\\nThen we have:\\n\\n(85)\\n\\n(86)\\n\\nProof: Consider the expected error on the training set:\\n\\n(87)\\n\\nConsider the cross-validation error:\\n\\np 0.5>\\n\\nE es( ) E f¬ X( ) f¬ X( )⊕( ) 0= =\\n\\nec f X( )¬ y2⊕=\\n\\nf¬ X( ) f X( ) z2⊕( )⊕=\\n\\nf¬ X( ) f X( )⊕( ) z2⊕=\\n\\nz¬ 2=\\n\\nE ec( ) E z¬ 2( ) E z¬ 2 i,\\ni 1=\\n\\nn\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 E z¬ 2 i,( )\\n\\ni 1=\\n\\nn\\n\\n∑ n 1 p−( )= = = =\\n\\net f¬ X( ) y1⊕ z¬ 1= =\\n\\nE et( ) E z¬ 1( ) E z¬ 2( ) E ec( ) n 1 p−( )= = = =\\n\\nE ec( ) z2\\n\\n.\\n\\nm X X yi,( ) yi=\\n\\nE et( ) 0=\\n\\nE ec( ) E es( ) 2np 2np2−= =\\n\\nE et( ) E m X X y1,( ) y1⊕( ) E y1 y1⊕( ) 0= = =\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 16\\n\\n(88)\\n\\n(89)\\n\\n(90)\\n\\n(91)\\n\\n(92)\\n\\nTherefore:\\n\\n(93)\\n\\n(94)\\n\\n(95)\\n\\n(96)\\n\\nConsider the expected instability:\\n\\n(97)\\n\\nThese theorems are variations on theorems that first appeared in Turney (1993).\\n\\nTheorems 2, 3, 4, and 5 in this paper correspond to Theorems 1, 12, 2, and 3 in Turney\\n\\n(1993). The difference is that the theorems in Turney (1993) cover real-valued variables,\\n\\nwhile the theorems here cover boolean-valued variables. A comparison will show that\\n\\nthere are interesting contrasts between the continuous case and the discrete case.\\n\\nWe shall call the model of Theorem 4 :\\n\\n(98)\\n\\nWe shall call the model of Theorem 5 :\\n\\n(99)\\n\\nLet us compare  for  and . Let  be  for :\\n\\nec m X X y1,( ) y2⊕=\\n\\ny1 y2⊕=\\n\\nf X( ) z1⊕( ) f X( ) z2⊕( )⊕=\\n\\nf X( ) f X( )⊕( ) z1 z2⊕( )⊕=\\n\\nz1 z2⊕=\\n\\nE ec( ) E z1 z2⊕( )=\\n\\nE z1 i, z2 i,⊕\\ni 1=\\n\\nn\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\nE z1 i, z2 i,⊕( )\\ni 1=\\n\\nn\\n\\n∑=\\n\\n2np 2np2−=\\n\\nE es( ) E m X X y1,( ) m X X y2,( )⊕( ) E y1 y2⊕( ) E ec( )= = =\\n\\n.\\n\\nmα\\n\\nmα X X yi,( ) f X( ) if p 0.5≤\\n\\nf X( )¬ if p 0.5>\\n=\\n\\nmβ\\n\\nmβ X X yi,( ) yi=\\n\\nE ec( ) mα mβ pα E ec( ) n⁄ mα\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 17\\n\\n(100)\\n\\nLet  be  for :\\n\\n(101)\\n\\nFigure 1 is a plot of  as a function of p, for  and .  has lower expected\\n\\ncross-validation error than , except at the points 0, 0.5, and 1, where  has the same\\n\\nexpected cross-validation error as . When p equals 0 or 1, there is no noise in the black\\n\\nbox, so  and  have the same expected cross-validation error. When p equals 0.5, the\\n\\nnoise completely hides the deterministic component f, so again  and  have the same\\n\\nexpected cross-validation error. In general, when p is neither 0, 0.5, nor 1, models that\\n\\nminimize error on the training set (such as ) will give sub-optimal cross-validation\\n\\nerror.\\n\\nFigure 1. Plot of as a function of p.\\n\\nThe next theorem shows the relation between  and .\\n\\npα\\np if p 0.5≤\\n\\n1 p−( ) if p 0.5>\\n=\\n\\npβ E ec( ) n⁄ mβ\\n\\npβ 2p 2p2−=\\n\\nE ec( ) n⁄ mα mβ mα\\n\\nmβ mα\\n\\nmβ\\n\\nmα mβ\\n\\nmα mβ\\n\\nmβ\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nmα\\n\\nmβ\\n\\np — probability of noise\\n\\nE\\ne c\\n\\n(\\n)\\n\\nn⁄\\n\\n—\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\ncr\\nos\\n\\ns-\\nva\\n\\nlid\\nat\\n\\nio\\nn \\n\\ner\\nro\\n\\nr\\n\\nE ec( ) n⁄\\n\\npα pβ\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 18\\n\\nTheorem 6: For :\\n\\n(102)\\n\\nProof: When , . Therefore we have:\\n\\n(103)\\n\\nWhen , . Therefore we have:\\n\\n(104)\\n\\n(105)\\n\\n(106)\\n\\nTheorem 6 shows that, for small values of p,  is approximately twice the optimal .\\n\\nAt this point, it may be worthwhile to summarize the assumptions that are made in this\\n\\ntheory:\\n\\n1. It is assumed that the inputs (the features; the attributes; the matrix X) are the same in\\n\\nthe training set  and the testing set . This assumption is the weakest ele-\\n\\nment in this theory. It is discussed in detail earlier in this section and also in Section 7.\\n\\nIt is also discussed in more depth in Turney (1993). Note that the outputs  and  are\\n\\nnot the same in the training and testing sets.\\n\\n2. It is assumed that the inputs are boolean-valued. This assumption is only used in The-\\n\\norem 1. The purpose of Theorem 1 is to increase the credibility of the above assump-\\n\\ntion 1. Theorem 1 can easily be adapted to the case of multi-valued symbolic\\n\\nattributes. Lemma 1 covers the case of real-valued attributes. Thus there is nothing\\n\\nessential about the assumption that the inputs are boolean-valued.\\n\\n3. It is assumed that the noise vector  is a sequence of n independent random boolean\\n\\nvariables, each having the value 1 with probability p. That is,  is a sequence of sam-\\n\\nples from a Bernoulli(p) distribution (Fraser, 1976). This is a very weak assumption,\\n\\nwhich is likely to be (approximately) satisfied in most real-world data (given assump-\\n\\ntion 6 below).\\n\\n0 p 1≤ ≤\\n\\npβ 2pα 2pα\\n2−=\\n\\n0 p 0.5≤ ≤ pα p=\\n\\npβ 2pα 2pα\\n2−=\\n\\n0.5 p< 1≤ pα 1 p−=\\n\\n2pα 2pα\\n2− 2 1 p−( ) 2 1 p−( ) 2−=\\n\\n2 2p− 2− 4p 2p2−+=\\npβ=\\n\\n.\\n\\npβ pα\\n\\nX y1( , ) X y2( , )\\n\\ny1 y2\\n\\nz\\n\\nz\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 19\\n\\n4. It is assumed that there is noise in the class attribute (assumption 3 above), but noise in\\n\\nthe input attributes is not addressed (due to assumption 1 above).\\n\\n5. It is assumed that the data consist of a deterministic component f and a random compo-\\n\\nnent z. This assumption is expressed in the model . One implication of\\n\\nthis assumption is that the target concept f does not drift with time or shift with con-\\n\\ntext.\\n\\n6. It is assumed that the output  (the class attribute) is boolean-valued. The theory can\\n\\neasily be extended to handle multi-valued symbolic class attributes. Turney (1993)\\n\\ndiscusses real-valued outputs (and real-valued noise vectors).\\n\\nWith the exception of the first assumption, these assumptions are relatively weak. 3\\n\\nThis section has presented some general results that apply to any algorithm for predict-\\n\\ning boolean-valued attributes. The rest of this paper focuses on a particular class of algo-\\n\\nrithms: instance-based learning algorithms. This section has presented a general theory\\n\\nand the remainder of the paper will demonstrate that the theory can be fruitfully applied to\\n\\na real, concrete machine learning algorithm.\\n\\n3  Single Nearest Neighbor\\nInstance-based learning may be used either for predicting boolean-valued attributes (Aha\\n\\net al., 1991) or for predicting real-valued attributes (Kibler et al., 1989). Instance-based\\n\\nlearning is a paradigm for a class of learning algorithms; it is not a single algorithm. It is\\n\\nrelated to the nearest neighbor pattern recognition paradigm (Dasarathy, 1991).\\n\\nWith instance-based learning, the model  is constructed by simply storing the\\n\\ndata . These stored data are the instances. In order to make a prediction for the input\\n\\n, we examine the row vectors  of the matrix X. In the simplest version of\\n\\ninstance-based learning, we look for the row vector  that is most similar to the input .\\n\\nThe prediction for the output is , the element of  that corresponds to the\\n\\nrow vector .\\n\\nThere are many ways that one might choose to measure the similarity between two\\n\\nvectors. It is assumed only that we are using a reasonable measure of similarity. Let us say\\n\\nthat a similarity measure  is reasonable if:\\n\\ny f v( ) z⊕=\\n\\ny\\n\\nm v X y,( )\\n\\nX y( , )\\n\\nv v1 …, vn,\\n\\nvi v\\n\\nm v X y,( ) yi= y\\n\\nvi\\n\\nsim u1 u2,( )\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 20\\n\\n(107)\\n\\nThat is, the similarity between distinct vectors is always less than the similarity between\\n\\nidentical vectors.\\n\\nThe k row vectors in X that are most similar to the input  are called the k nearest\\n\\nneighbors of  (Dasarathy, 1991). We may use  to represent instance-based learning\\n\\nwith k nearest neighbors. This section focuses on .\\n\\nThe next theorem shows that instance-based learning  using the single nearest\\n\\nneighbor gives sub-optimal cross-validation error.\\n\\nTheorem 7: Let the model  use instance-based learning with the single nearest\\n\\nneighbor. That is, if the row vector  is the most similar to the input  of all the row\\n\\nvectors  of the matrix X, then . If  uses a reasonable measure of\\n\\nsimilarity and no two rows in X are identical, then .\\n\\nProof: Since  is based on a reasonable measure of similarity and no two rows in X are\\n\\nidentical, no vector is more similar to  than  itself, so . Thus it follows\\n\\nfrom (21) that\\n\\nTheorem 7 shows that  satisfies the assumptions of Theorem 5. Therefore  has the\\n\\nfollowing properties:\\n\\n(108)\\n\\n(109)\\n\\nIn other words,  is equivalent to . We know from Section 2 that  gives sub-\\n\\noptimal cross-validation error.\\n\\nIf there are two (or more) identical rows in X, then (109) still holds, but (108) is not\\n\\nnecessarily true.  will, in general, no longer be equivalent to . The proof is a small\\n\\nvariation on Theorem 5.\\n\\nThe problem with  is that it is unstable. It is natural to consider increasing the\\n\\nstability of instance-based learning by considering .\\n\\nu1 u2≠ sim u1 u2,( ) sim u1 u1,( )<→\\n\\nv\\n\\nv mk\\n\\nk 1=\\n\\nm1\\n\\nm1\\n\\nvi v\\n\\nv1 …, vn, m1 v X y,( ) yi= m1\\n\\nm1 X X y,( ) y=\\n\\nm1\\n\\nvi vi m1 vi X y,( ) yi=\\n\\nm X X y,( ) y= .\\n\\nm1 m1\\n\\nE et( ) 0=\\n\\nE ec( ) E es( ) 2np 2np2−= =\\n\\nm1 mβ m1\\n\\nm1 mβ\\n\\nm1\\n\\nk 1>\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 21\\n\\n4  Voting\\n\\nThis section examines . Suppose the model  is given the input vector . Let\\n\\n be the k nearest neighbors to . That is, let  be the k row vectors in X\\n\\nthat are most similar to the input vector . Let us assume a reasonable measure of similar-\\n\\nity. Let  be the outputs corresponding to the rows . The model\\n\\npredicts the output for the input  to be the value of the majority of  (Fix &\\n\\nHodges, 1951):\\n\\n(110)\\n\\nLet us assume that k is an odd number, , so there will never be a tie in\\n\\nmajority voting with . Of course, we require that . In general, .\\n\\nMore generally, let us consider the following model (Tomek, 1976):\\n\\n(111)\\n\\nIn this model, t is a threshold, such that . With majority voting, . When\\n\\n, it may be appropriate to consider values of k other than the odd numbers.\\n\\nThe motivation for voting is the belief that it will increase stability; that it will make\\n\\nthe model more resistant to noise in the data. The following sections give a formal analysis\\n\\nof the stability of instance-based learning with voting. They examine the best case, the\\n\\nworst case, and the average case.\\n\\n4.1  Best Case\\n\\nThe next theorem concerns the best case, when stability is maximal.\\n\\nTheorem 8: Let  be the set of the k nearest neighbors  to . Let  be\\n\\nk 1≥ mk v\\n\\nv1 … vk, , v v1 … vk, ,\\n\\nv\\n\\ny1 … yk, , v1 … vk, , mk\\n\\nv y1 … yk, ,\\n\\nmk v X y,( )\\n0 if yi\\n\\ni 1=\\n\\nk\\n\\n∑ k 2⁄<\\n\\n1 if yi\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\n=\\n\\nk 3 5 7 …, , ,=\\n\\ny1 … yk, , k n≤ k n«\\n\\nmk v X y,( )\\n0 if yi\\n\\ni 1=\\n\\nk\\n\\n∑ tk<\\n\\n1 if yi\\ni 1=\\n\\nk\\n\\n∑ tk>\\n\\n=\\n\\n0 t 1< < t 0.5=\\n\\nt 0.5≠\\n\\nNk vi( ) v1 … vk, , vi ρi\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 22\\n\\ndefined as follows:\\n\\n(112)\\n\\nThat is,  is the frequency with which f takes the value 1, in the neighborhood  of\\n\\n. Assume that we are using majority voting, , and that . Suppose\\n\\nthat:\\n\\n(113)\\n\\nThis is the most stable situation; other values of  are less stable.  for  is deter-\\n\\nmined by the following formula:\\n\\n(114)\\n\\nIn this formula,  depends on .  has the following values for , , , and :\\n\\n(115)\\n\\n(116)\\n\\n(117)\\n\\n(118)\\n\\nProof: Let  be the k nearest neighbors to . Let  be the correspond-\\n\\ning elements in . Let  be the corresponding elements in . The stability of\\n\\n is determined by the probability that:\\n\\n(119)\\n\\nIf we can find this probability for each row vector in X, then we can find the stability of\\n\\n. Suppose that  is the probability of (119) when the input to  is . Then  is the\\n\\nprobability that:\\n\\n(120)\\n\\nρi\\n1\\nk\\n\\nf vj( )\\nvj Nk vi( )∈\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6= i 1 … n, ,=\\n\\nρi Nk vi( )\\n\\nvi t 0.5= k 3 5 7 …, , ,=\\n\\ni∀( ) ρi 0=( ) ρi 1=( )∨( )\\n\\nρi E es( ) mk\\n\\nE es( ) 2nPk 2nPk\\n2−=\\n\\nPk mk Pk m1 m3 m5 m∞\\n\\nP1 p=\\n\\nP3 3p2 2p3−=\\n\\nP5 6p5 15p4− 10p3+=\\n\\nP∞\\n\\n0 if p 0.5<\\n0.5 if p 0.5=\\n1 if p 0.5>\\n\\n=\\n\\nv1 … vk, , v y1 1, … y1 k,, ,\\n\\ny1 y2 1, … y2 k,, , y2\\n\\nmk\\n\\ny1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄< and y2 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\nmk pi mk vi 2pi\\n\\nmk vi X y1,( ) mk vi X y2,( )⊕ 1=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 23\\n\\nTherefore:\\n\\n(121)\\n\\nThe best case — the case with minimal expected instability  — arises when\\n\\n or . Without loss of generality, we may assume that . In this case,\\n\\nwe have:\\n\\n(122)\\n\\nTherefore (119) becomes:\\n\\n(123)\\n\\nLet us introduce the term :\\n\\n(124)\\n\\nThat is,  is the probability that the majority of  are 1, given that\\n\\n are all 0. The probability of (119) is:\\n\\n(125)\\n\\nIf the best case holds for every row vector in X — that is, if (113) is true — then we have:\\n\\n(126)\\n\\nLet us consider the case . We have:\\n\\n(127)\\n\\nRecall that for  we have (109):\\n\\n(128)\\n\\nThus . For , we have:\\n\\n(129)\\n\\nE es( ) E mk vi X y1,( ) mk vi X y2,( )⊕( )\\ni 1=\\n\\nn\\n\\n∑ 2pi\\ni 1=\\n\\nn\\n\\n∑= =\\n\\nE es( )\\n\\nρi 0= ρi 1= ρi 0=\\n\\nyi j, f vj( ) zi j,⊕ 0 zi j,⊕ zi j,= = = i 1 2,= j 1 … k, ,=\\n\\nz1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄< and z2 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\nPk\\n\\nPk P z1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\nPk y1 1, … y1 k,, ,\\n\\nf v1( ) …, f vk( ),\\n\\nPk 1 Pk−( )\\n\\nE es( ) 2Pk 1 Pk−( )\\ni 1=\\n\\nn\\n\\n∑ 2nPk 1 Pk−( )= =\\n\\nk 3=\\n\\nP3 p3 3p2 1 p−( )+ p3 3p2 3p3−+ 3p2 2p3−= = =\\n\\nk 1=\\n\\nE es( ) 2np 2np2−=\\n\\nP1 p= k 5=\\n\\nP5 6p5 15p4− 10p3+=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 24\\n\\nTo find the behavior of the model in the limit, , we can use the Central Limit Theorem\\n\\n(Fraser, 1976). Consider the following sum:\\n\\n(130)\\n\\nThe mean and variance of this sum are:\\n\\n(131)\\n\\n(132)\\n\\nConsider the following expression:\\n\\n(133)\\n\\nBy the Central Limit Theorem, the distribution of (133) approaches a standard normal dis-\\n\\ntribution as k approaches infinity. Recall the definition of :\\n\\n(134)\\n\\nLet  be a random variable with a standard normal distribution. As k approaches infinity,\\n\\n approaches:\\n\\n(135)\\n\\nWe see that:\\n\\n(136)\\n\\nTherefore:\\n\\nm∞\\n\\nz1 i,\\ni 1=\\n\\nk\\n\\n∑\\n\\nE z1 i,\\ni 1=\\n\\nk\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 kp=\\n\\nvar z1 i,\\ni 1=\\n\\nk\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 kp 1 p−( )=\\n\\nz1 i,\\ni 1=\\n\\nk\\n\\n∑ kp−\\n\\nkp 1 p−( )\\n\\nPk\\n\\nPk P z1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\nzα\\n\\nPk\\n\\nP zα\\nk 2⁄( ) kp−\\nkp 1 p−( )\\n\\n>\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6\\n\\nk 2⁄( ) kp−\\nkp 1 p−( )\\uf8ed \\uf8f8\\n\\n\\uf8eb \\uf8f6\\nk ∞→\\nlim\\n\\n∞ if p 0.5<\\n0 if p 0.5=\\n∞− if p 0.5>\\n\\n=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 25\\n\\n(137)\\n\\n(138)\\n\\nTheorem 8 implies that, in the best case,  grows increasingly stable as k increases,\\n\\nunless . Figure 2 is a plot of  as a function of p, for the models , ,\\n\\n, and .\\n\\nFigure 2. A plot of  as a function of p.\\n\\nWhen comparing Figure 1 with Figure 2, note that Figure 1 is a plot of ,\\n\\nwhile Figure 2 is a plot of . In general, we cannot plot  for ,\\n\\nbecause  will depend on the data. Theorems 2 and 3 show that  depends on\\n\\nboth  and . The exception is , where we know that .\\n\\nP∞\\n\\n0 if p 0.5<\\n0.5 if p 0.5=\\n1 if p 0.5>\\n\\n=\\n\\nE es( )\\nn\\n\\n2P∞ 1 P∞−( ) 0 if p 0.5≠\\n0.5 if p 0.5=\\n\\n= =\\n\\n.\\n\\nmk\\n\\np 0.5= E es( ) n⁄ m1 m3\\n\\nm5 m∞\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm5\\n\\nm1\\n\\nm3\\n\\nm∞\\n\\np — probability of noise\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\nE es( ) n⁄\\n\\nE ec( ) n⁄\\n\\nE es( ) n⁄ E ec( ) n⁄ mk\\n\\nE et( ) E ec( )\\n\\nE es( ) E et( ) m1 E et( ) 0=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 26\\n\\n(Recall that .)\\n\\nTheorem 8 does not necessarily mean that we should make k as large as possible, even\\n\\nif we assume that the best case (113) holds. It is assumed that our goal is to minimize the\\n\\nexpected cross-validation error. Theorems 2 and 3 show that the expected cross-validation\\n\\nerror has two components, the error on the training set and the instability. In the best case,\\n\\nincreasing k will increase stability, but increasing k is also likely to increase the error on\\n\\nthe training set. We must find the value of k that best balances the conflicting demands of\\n\\naccuracy (low error on the training set) and stability (resistance to noise). This value will,\\n\\nof course, depend on f and p.\\n\\n4.2  Worst Case\\n\\nThe next theorem concerns the worst case, when stability is minimal.\\n\\nTheorem 9: Assume that we are using majority voting, , and that .\\n\\nSuppose that:\\n\\n(139)\\n\\nThis is the least stable situation; other values of  are more stable.  for  is\\n\\ndetermined by the following formula:\\n\\n(140)\\n\\nIn this formula,  depends on .  has the following values for , , , and :\\n\\n(141)\\n\\n(142)\\n\\n(143)\\n\\n(144)\\n\\nProof: Let  be the k nearest neighbors to . Let  be the correspond-\\n\\ning elements in . Let  be the corresponding elements in . The stability of\\n\\nm1 mβ=\\n\\nt 0.5= k 3 5 7 …, , ,=\\n\\ni∀( ) ρi\\n1\\n2\\n\\n1\\n2k\\n\\n+= ρi\\n1\\n2\\n\\n1\\n2k\\n\\n−=∨\\n\\nρi E es( ) mk\\n\\nE es( ) 2nPk 2nPk\\n2−=\\n\\nPk mk Pk m1 m3 m5 m∞\\n\\nP1 p=\\n\\nP3 2p 3p2− 2p3+=\\n\\nP5 3p 9p2− 16p3 15p4− 6p5+ +=\\n\\nP∞\\n\\n0 if p 0=\\n0.5 if 0 p 1< <\\n\\n1 if p 1=\\n=\\n\\nv1 … vk, , v y1 1, … y1 k,, ,\\n\\ny1 y2 1, … y2 k,, , y2\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 27\\n\\n is determined by the probability that:\\n\\n(145)\\n\\nThe worst case — the case with maximal expected instability  — arises when:\\n\\n(146)\\n\\nWithout loss of generality, we may assume that:\\n\\n(147)\\n\\n(148)\\n\\n(149)\\n\\nWe see that:\\n\\n(150)\\n\\n(151)\\n\\nTherefore:\\n\\n(152)\\n\\nWe may use the term  to indicate the probability of (152). That is,  is the probability\\n\\nthat the majority of  are 1, given (148) and (149). If the worst case holds for\\n\\nevery row vector in X — that is, (139) is true — then we have:\\n\\n(153)\\n\\nLet us consider the case . We have:\\n\\n(154)\\n\\nFor , we have:\\n\\n(155)\\n\\nmk\\n\\ny1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄< and y2 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\nE es( )\\n\\nf vi( )\\ni 1=\\n\\nk\\n\\n∑ k 1+\\n2\\n\\n= or f vi( )\\ni 1=\\n\\nk\\n\\n∑ k 1−\\n2\\n\\n=\\n\\ns\\nk 1+\\n\\n2\\n=\\n\\nf v1( ) … f vs( ) 1= = =\\n\\nf vs 1+( ) … f vk( ) 0= = =\\n\\nyi j, zi j,¬= i 1 2,= j 1 … s, ,=\\n\\nyi j, zi j,= i 1 2,= j s 1+ … k, ,=\\n\\nP y1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 P z1 i,\\n\\ni 1=\\n\\ns\\n\\n∑ z1 i,\\ni s 1+=\\n\\nk\\n\\n∑≤\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\nPk Pk\\n\\ny1 1, … y1 k,, ,\\n\\nE es( ) 2Pk 1 Pk−( )\\ni 1=\\n\\nn\\n\\n∑ 2nPk 1 Pk−( )= =\\n\\nk 3=\\n\\nP3 2p 3p2− 2p3+=\\n\\nk 5=\\n\\nP5 3p 9p2− 16p3 15p4− 6p5+ +=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 28\\n\\nAgain, to find the behavior  of the model in the limit, we can use the Central Limit\\n\\nTheorem. Let  and  be independent random variables with a standard normal distribu-\\n\\ntion. As k approaches infinity,  approaches:\\n\\n(156)\\n\\nTherefore:\\n\\n(157)\\n\\n(158)\\n\\nTheorem 9 implies that, in the worst case,  grows increasingly unstable as k increases,\\n\\nunless  or . Figure 3 is a plot of  as a function of p, for the models\\n\\n, , , and .\\n\\nFigure 3. A plot of  as a function of p.\\n\\nm∞\\n\\nzα zβ\\n\\nPk\\n\\nP zα zβ≤( )\\n\\nP∞\\n\\n0 if p 0=\\n0.5 if 0 p 1< <\\n\\n1 if p 1=\\n=\\n\\nE es( )\\nn\\n\\n2P∞ 1 P∞−( ) 0 if p 0=( ) or p 1=( )\\n0.5 if 0 p 1< <\\n\\n= =\\n\\n.\\n\\nmk\\n\\np 0= p 1= E es( ) n⁄\\n\\nm1 m3 m5 m∞\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm5\\n\\nm1\\n\\nm3\\n\\nm∞\\n\\np — probability of noise\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\nE es( ) n⁄\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 29\\n\\n4.3  Average Case\\n\\nSections 4.1 and 4.2 show that voting can be either very beneficial or very detrimental,\\n\\ndepending on the relationship between the function f and the voting threshold t. The\\n\\nfunction f determines , the frequency with which f takes the value 1, in the neighbor-\\n\\nhood  of . In the previous sections, we assumed majority voting, . When\\n\\n is near 0.5, majority voting is detrimental. When  is far from 0.5, majority voting is\\n\\nbeneficial. These results generalize to voting with other values of t. When  is near t,\\n\\nvoting is detrimental. When  is far from t, voting is beneficial.\\n\\nWe would like to know how majority voting performs with an average f. For the\\n\\naverage function f, is  dangerously close to 0.5, or is it usually safely far away? This is a\\n\\ndifficult question: What exactly is an average f?\\n\\nThe next theorem uses a simple model of an average f.\\n\\nTheorem 10: Assume that we are using majority voting, . Let us suppose that we\\n\\ncan treat  as a random boolean variable, with probability  that  is 1, and proba-\\n\\nbility  that  is 0. In the limit, as k approaches infinity,  tends to be stable,\\n\\nunless either  or .\\n\\nProof: We see that:\\n\\n(159)\\n\\nRecall that:\\n\\n(160)\\n\\nTherefore:\\n\\n(161)\\n\\n(162)\\n\\nThus:\\n\\n(163)\\n\\nρi\\n\\nNk vi( ) vi t 0.5=\\n\\nρi ρi\\n\\nρi\\n\\nρi\\n\\nρi\\n\\nt 0.5=\\n\\nf vi( ) p' f vi( )\\n\\n1 p'− f vi( ) mk\\n\\np 0.5= p' 0.5=\\n\\nE f vi( )\\ni 1=\\n\\nk\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 kp'=\\n\\nyi j, f vj( ) zi j,⊕= i 1 2,= j 1 … k, ,=\\n\\nP yi j, 0=( ) 1 p'−( ) 1 p−( ) p'p+=\\n\\nP yi j, 1=( ) p 1 p'−( ) p' 1 p−( )+=\\n\\nE y1 i,\\ni 1=\\n\\nk\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 k p 1 p'−( ) p' 1 p−( )+[ ] µ= =\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 30\\n\\n(164)\\n\\nConsider:\\n\\n(165)\\n\\nBy the Central Limit Theorem, as k approaches infinity, (165) approaches a standard\\n\\nnormal distribution. As before, we define  as the probability:\\n\\n(166)\\n\\nLet  be a random variable with a standard normal distribution. As k approaches infinity,\\n\\n approaches:\\n\\n(167)\\n\\nWe see that:\\n\\n(168)\\n\\nTherefore:\\n\\n(169)\\n\\n(170)\\n\\nThus  tends to be stable, unless:\\n\\n(171)\\n\\nvar y1 i,\\ni 1=\\n\\nk\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6 k p 1 p'−( ) p' 1 p−( )+[ ] 1 p'−( ) 1 p−( ) p'p+[ ] σ2= =\\n\\ny1 i,\\ni 1=\\n\\nk\\n\\n∑ µ−\\n\\nσ\\n\\nPk\\n\\nP y1 i,\\ni 1=\\n\\nk\\n\\n∑ k 2⁄>\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6\\n\\nzα\\n\\nPk\\n\\nP zα k 2⁄( ) µ−( ) σ⁄>( )\\n\\nk 2⁄( ) µ−( ) σ⁄( )\\nk ∞→\\nlim\\n\\n∞ if p 1 p'−( ) p' 1 p−( )+[ ] 0.5<\\n0 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5=\\n∞− if p 1 p'−( ) p' 1 p−( )+[ ] 0.5>\\n\\n=\\n\\nP∞\\n\\n0 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5<\\n0.5 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5=\\n1 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5>\\n\\n=\\n\\nE es( )\\nn\\n\\n2P∞ 1 P∞−( ) 0 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5≠\\n0.5 if p 1 p'−( ) p' 1 p−( )+[ ] 0.5=\\n\\n= =\\n\\nmk\\n\\np 1 p'−( ) p' 1 p−( )+ 0.5=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 31\\n\\nSome algebraic manipulation converts (171) to:\\n\\n(172)\\n\\nTherefore  tends to be stable, unless either  or\\n\\nLet us now consider the general case (111), when the threshold for voting t is not nec-\\n\\nessarily equal to 0.5.\\n\\nTheorem 11: Let t be any value, such that . Let us suppose that we can treat\\n\\nas a random boolean variable, with probability  that  is 1, and probability  that\\n\\n is 0. Let us introduce the term :\\n\\n(173)\\n\\nIn the limit, as k approaches infinity,  tends to be stable, unless .\\n\\nProof: This is a straightforward extension of the reasoning in Theorem 10\\n\\nPresumably p (the probability that z is 1) and  (the probability that f is 1) are not under\\n\\nthe control of the modeler. However, t can be adjusted by the modeler. If the modeler can\\n\\nestimate p and , then  can be estimated. Theorem 11 implies that the modeler should\\n\\nmake sure that t is relatively far from .\\n\\nThe assumption that we can treat  as a random boolean variable is somewhat unre-\\n\\nalistic. Let us consider a more sophisticated analysis.\\n\\nTheorem 12: Let us define  as follows:\\n\\n(174)\\n\\nIn the limit, as k approaches infinity,  tends to be stable for , unless t is close to .\\n\\nProof: This is a straightforward extension of the reasoning in Theorem 10\\n\\nLet us define  as the average of the :\\n\\n(175)\\n\\nNote that:\\n\\n2p 1−( ) 1 2p'−( ) 0=\\n\\nmk p 0.5= p' 0.5= .\\n\\n0 t 1< < f vi( )\\n\\np' f vi( ) 1 p'−\\n\\nf vi( ) τ\\n\\nτ p 1 p'−( ) p' 1 p−( )+ p p' 2pp'−+= =\\n\\nmk t τ=\\n\\n.\\n\\np'\\n\\np' τ\\n\\nτ\\n\\nf vi( )\\n\\nτi\\n\\nτi p ρi 2pρi−+= i 1 … n, ,=\\n\\nmk vi τi\\n\\n.\\n\\np' ρi\\n\\np'\\n1\\nn\\n\\nρi\\ni 1=\\n\\nn\\n\\n∑=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 32\\n\\n(176)\\n\\nWe can use (173) and (175) to calculate . Theorem 12 implies that it is possible for  to\\n\\nbe stable even when , if t is far from each .\\n\\nTheorem 13: We can estimate  from the data  as follows:\\n\\n(177)\\n\\n is an unbiased estimator for .\\n\\nProof: We have:\\n\\n(178)\\n\\n(179)\\n\\n(180)\\n\\n(181)\\n\\nUsing (177), we can estimate  for any k and any i.  is the frequency of the output 1, in\\n\\nthe neighborhood  of .\\n\\nTheorem 14: If we know the value of p, then we can also estimate  from the data\\n\\n:\\n\\n(182)\\n\\n is an unbiased estimator for .\\n\\nProof: We have:\\n\\np'\\n1\\nn\\n\\nf vi( )\\ni 1=\\n\\nn\\n\\n∑≠\\n\\nτ mk\\n\\nt τ= τi\\n\\nτi X y1( , )\\n\\nti\\n1\\nk\\n\\ny1 j,\\nvj Nk vi( )∈\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6= i 1 … n, ,=\\n\\nti τi\\n\\nE ti( ) 1\\nk\\n\\nE y1 j,( )\\nvj Nk vi( )∈\\n\\n∑\\n\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\n1\\nk\\n\\nE f vj( ) z1 j,⊕( )\\nvj Nk vi( )∈\\n\\n∑\\uf8ed \\uf8f8\\n\\uf8eb \\uf8f6=\\n\\np ρi 2pρi−+=\\n\\nτi=\\n\\n.\\n\\nτi ti\\n\\nNk vi( ) vi\\n\\nρi\\n\\nX y1( , )\\n\\nri\\n\\nti p−\\n1 2p−=\\n\\nri ρi\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 33\\n\\n(183)\\n\\n(184)\\n\\n(185)\\n\\n(186)\\n\\nUsing (177) and (182), we can estimate  for any k and any i. Once we have an estimate\\n\\nof , we can establish whether we are closer to the best case (Section 4.1) or the worst\\n\\ncase (Section 4.2).\\n\\nWe now have some understanding of the average behavior of  in the limit. Let us\\n\\nconsider the average behavior of  for  and .\\n\\nTheorem 15: Suppose that n is even. Let  and . Suppose that:\\n\\n(187)\\n\\n(188)\\n\\nThen:\\n\\n(189)\\n\\nProof: We know from Section 4.2 that  is unstable when:\\n\\n(190)\\n\\nWe know from Section 4.1 that  is stable when:\\n\\n(191)\\n\\nFor the unstable case, , we have (154):\\n\\n(192)\\n\\nFor the stable case, , we have (127):\\n\\n(193)\\n\\nTherefore (126):\\n\\nE ri( )\\nE ti( ) p−\\n1 2p−=\\n\\nτi p−( ) 1 2p−( )⁄=\\n\\np ρi 2pρi−+ p−( ) 1 2p−( )⁄=\\n\\nρi=\\n\\n.\\n\\nρi\\n\\nρi\\n\\nmk\\n\\nmk k 3= t 0.5=\\n\\nk 3= t 0.5=\\n\\nρi 1 3⁄= or ρi 2 3⁄= i 1 … n 2⁄, ,=\\n\\nρi 0 3⁄= or ρi 3 3⁄= i n 2⁄ 1+ … n, ,=\\n\\nE es( ) n 2p 4p2− 12p3 26p4− 24p5 8p6−+ +( )=\\n\\nm3\\n\\nρi 1 3⁄= or ρi 2 3⁄= i 1 … n, ,=\\n\\nm3\\n\\nρi 0 3⁄= or ρi 3 3⁄= i 1 … n, ,=\\n\\ni 1 … n 2⁄, ,=\\n\\nPu 3, 2p 3p2− 2p3+=\\n\\ni n 2⁄ 1+ … n, ,=\\n\\nPs 3, 3p2 2p3−=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 34\\n\\n(194)\\n\\n(195)\\n\\n(196)\\n\\n(197)\\n\\nFigure 4 is a plot of  for , using the average case analysis of Theorem 15.\\n\\nFor comparison,  is also plotted for .  is slightly more stable than ,\\n\\nexcept at 0, 0.5, and 1, where they are equal.\\n\\nFigure 4. A plot of  as a function of p.\\n\\n5  Application\\n\\nLet us assume that n, p, X, and  are fixed, while k and t are under our control. Our goal is\\n\\nto minimize the expected cross-validation error. The data X and  are the training set, and\\n\\nthe testing set is not yet available to us. How do we determine the best values for k and t?\\n\\nE es( ) 2Pu 3, 1 Pu 3,−( )\\ni 1=\\n\\nn 2⁄\\n\\n∑ 2Ps 3, 1 Ps 3,−( )\\ni n 2⁄ 1+=\\n\\nn\\n\\n∑+=\\n\\nn\\n2\\n\\n2Pu 3, 1 Pu 3,−( ) n\\n2\\n\\n2Ps 3, 1 Ps 3,−( )+=\\n\\nn Pu 3, Pu 3,\\n2− Ps 3, Ps 3,\\n\\n2−+[ ]=\\n\\nn 2p 4p2− 12p3 26p4− 24p5 8p6−+ +( )=\\n\\n.\\n\\nE es( ) n⁄ m3\\n\\nE es( ) n⁄ m1 m3 m1\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm1\\n\\nm3\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\np — probability of noise\\n\\nE es( ) n⁄\\n\\ny\\n\\ny\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 35\\n\\nUsing Theorems 2 or 3, we can estimate  if we can estimate  and .\\n\\nObtaining an estimate of  is relatively simple. We can use the actual error on\\n\\nthe training set  as an estimator for the expected error on the training set . By\\n\\nthe Law of Large Numbers (Fraser, 1976), as n increases,  becomes increasingly\\n\\nclose to .\\n\\nObtaining an estimate of  is more difficult. Suppose , , and the\\n\\nvalue of p is known by the modeler. We can use Theorem 14 to estimate  for\\n\\n. We can then use the method of Theorem 15 to obtain an estimate of .\\n\\nTo estimate , we need to know p, the level of noise in the black box. We can estimate\\n\\np empirically from the data (by assuming that f is usually constant within a small neigh-\\n\\nborhood, for example), or we can theoretically analyze the internal mechanism of the\\n\\nblack box. A mixed approach, combining theoretical and empirical analysis, may be\\n\\nfruitful.\\n\\nThis approach to estimating  is feasible for  or , but the algebra\\n\\nbecomes exponentially messy for larger values of k. For large values of k, we can use\\n\\nTheorem 13 to estimate . Theorem 12 suggests that  will tend toward 0, as long\\n\\nas  is far enough from t, for all i.\\n\\nOnce we have an estimate of  and , we can use Theorem 2 to set an\\n\\nupper bound on . Alternatively, we can use Theorem 3 to estimate . (It is\\n\\nconjectured that  satisfies the assumption of Theorem 3, that  and  are statistically\\n\\nindependent, but there is not yet a proof for this.) We can estimate  for varying\\n\\nvalues of k and t. We should then choose the values of k and t that minimize our estimated\\n\\nexpected cross-validation error.\\n\\nThe average-case analysis of the previous section suggests that increasing k will tend\\n\\nto increase stability. Increasing k will also tend to increase training set error. If we plot\\n\\ncross-validation error as a function of k, then we expect to see a curve with a single\\n\\nminimum at the optimal value of k, somewhere between the extremes  and .\\n\\nEmpirical tests of nearest neighbor algorithms report exactly this result (Dasarathy, 1991).\\n\\nI have not included any empirical tests with real-world data in this paper, because it would\\n\\nE ec( ) E et( ) E es( )\\n\\nE et( )\\n\\net E et( )\\n\\net n⁄\\n\\nE et( ) n⁄\\n\\nE es( ) k 3= t 0.5=\\n\\nρi\\n\\ni 1 … n, ,= E es( )\\n\\nρi\\n\\nE es( ) k 3= k 5=\\n\\nτi E es( )\\n\\nτi\\n\\nE et( ) E es( )\\n\\nE ec( ) E ec( )\\n\\nmk et es\\n\\nE ec( )\\n\\nk 1= k n=\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 36\\n\\nmerely duplicate work that has already been done. That is, the average-case analysis\\n\\npresented here is consistent with typical empirical experience.\\n\\nThe worst-case analysis, on the other hand, yields a surprising result, that increasing k\\n\\ncan actually decrease stability. In the worst case, if we plot cross-validation error as a\\n\\nfunction of k, then we may see a curve with a minimum at , that steadily rises as k\\n\\nincreases. It is sometimes reported that cross-validation error is minimal at , but it is\\n\\nusually assumed that this is due to rapid increase in training set error with increasing k,\\n\\nrather than decrease in stability with increasing k. It seems likely that the worst case,\\n\\nwhere stability decreases as k increases, is very rare in real-world data. Thus it would be\\n\\ndifficult to find real-world data that illustrates the worst-case analysis. Simulated data\\n\\ncould be used, but there would be no point in such an exercise, since the results would be\\n\\ndetermined by the assumptions embedded in the simulation. Therefore this paper does not\\n\\ninclude any empirical results.\\n\\n6  Related Work\\nThis work is most closely related to Turney (1993), which presents a general theory of\\n\\ncross-validation error for algorithms that predict real-valued attributes. The theory is then\\n\\napplied to linear regression and instance-based learning. The theory of cross-validation\\n\\nerror for algorithms that predict boolean-valued attributes, presented in Section 2, is\\n\\nsimilar to the theory for real-valued attributes (Turney, 1993), but there are some differ-\\n\\nences. Real-valued noise is quite different from boolean-valued noise. Boolean noise z is a\\n\\nrandom variable in , such that the probability that z is 1 is p. Real noise z is a random\\n\\nvariable in , such that z has mean 0 and variance . Equivalently, the noise is ,\\n\\nwhere z has mean 0 and variance 1. The role of p in boolean noise is similar to the role of\\n\\n in real noise, except that p must be in the range , but the range of  is . This\\n\\nmakes a substantial difference in the details of the two cases, real-valued and boolean-\\n\\nvalued.\\n\\nTurney (1993) also examined the cross-validation error of instance-based learning\\n\\nwith k nearest neighbors. When instance-based learning is used to predict real-values, the\\n\\nk nearest neighbors are averaged together (Kibler et al., 1989). Averaging the k nearest\\n\\nneighbors for real-valued attributes is analogous to voting for boolean-valued attributes.\\n\\nThere is a surprising difference, however. Turney (1993) proves that averaging, in the best\\n\\ncase, improves stability and, in the worst case, does not affect stability (Theorem 10 in\\n\\n(Turney, 1993)). Voting, in the worst case, can be destabilizing (Section 4.2). It is surpris-\\n\\nk 1=\\n\\nk 1=\\n\\n0 1{ , }\\n\\nℜ σ2 σz\\n\\nσ 0 1[ , ] σ ℜ+\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 37\\n\\ning to discover this break in the analogy between the real-valued case and the boolean-\\n\\nvalued case.\\n\\nTurney (1993) mentions that the theory of cross-validation error is similar to the work\\n\\nin Akaike Information Criterion (AIC) statistics (Sakamoto et al., 1986). The similarity\\n\\nstems from the idea of finding the best model  for one set of outputs , then\\n\\nevaluating the model’s performance with a second set of outputs . This is the definition\\n\\nof the expected cross-validation error. Akaike uses the same approach to define mean\\n\\nexpected log likelihood (Sakamoto et al., 1986). For a more thorough comparison of the\\n\\napproach described here with AIC, see Turney (1993).\\n\\nThere is an interesting connection between the work here and previous work in nearest\\n\\nneighbor pattern classification. Cover and Hart (1967) assume that n is large and the prob-\\n\\nability distribution for  is a continuous function of . Using Lemma 1, they\\n\\nprove the following Theorem:\\n\\n(198)\\n\\nHere, R is the probability of error of ,  is the Bayes probability of error, and M is the\\n\\nnumber of categories. The Bayes probability of error is the minimum probability of error\\n\\nover all decision rules taking underlying probability structure into account (Cover & Hart,\\n\\n1967). This paper assumes boolean-valued attributes, so :\\n\\n(199)\\n\\nCompare this with Theorem 6:\\n\\n(200)\\n\\nThere are clearly some similarities between (199) and (200). However, there are also some\\n\\ndifferences. (200) is an exact equality, while (199) is an inequality. The reason for this dif-\\n\\nference is that Cover and Hart’s (1967) noise, , is a function of , while the noise z\\n\\ndiscussed here is not a function of . To remove the dependence on , Cover and Hart\\n\\n(1967) define R and  as the expected probabilities, where the expectation is taken over\\n\\n. This makes their proof more complex than mine.\\n\\nCover and Hart’s (1967) Lemma is similar to Theorem 1 here. Their Theorem is\\n\\nsimilar to Theorem 6 here. They do not have any results comparable to Theorems 2 and 3.\\n\\nThat is, they do not separate cross-validation error into two components, accuracy and\\n\\nm X X y1,( ) y1\\n\\ny2\\n\\nP f v( ) z⊕ 1=( ) v\\n\\nR* R R* 2 MR* M 1−( )⁄−( )≤ ≤\\n\\nm1 R*\\n\\nM 2=\\n\\nR* R 2R 2 R*( ) 2−≤ ≤\\n\\npβ 2pα 2pα\\n2−=\\n\\nz v( ) v\\n\\nv v\\n\\nR*\\n\\nv\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 38\\n\\nstability. It is this separation which enables me to achieve the results of Section 4. Section\\n\\n4 does not correspond to any previous work with nearest neighbor pattern classification.\\n\\nSection 4 is evidence in favor of the two-component view of cross-validation error.\\n\\nWe know from Section 3 that  has maximal accuracy, since . In\\n\\ngeneral,  will be less accurate than , but  will also be more stable than . As k\\n\\nincreases, we expect that accuracy decreases (error on the training set increases) and\\n\\nstability increases. At some point, as k increases, further increase in stability will not suffi-\\n\\nciently compensate for the decrease in accuracy. Section 5 shows how we can find the\\n\\nvalue of k that gives the best balance between accuracy and stability. It is certainly\\n\\npossible, for a certain set of data, that the best balance is . This is not a new insight.\\n\\nCover and Hart (1967) prove that there are situations in which  has a lower probability\\n\\nof error than , where . What is new is the observation that there are situations in\\n\\nwhich, as k increases, stability may decrease (see Section 4.2). Thus both accuracy and\\n\\nstability decrease. Section 5 shows how we may detect such situations, using the estima-\\n\\ntors  for  and  for .\\n\\nAha et al. (1991) also examine k nearest neighbor algorithms, but their analysis is a\\n\\nworst-case analysis, assuming certain probability distributions. They also assume\\n\\nnumeric-valued attributes.\\n\\nLangley (1993) also presents an average-case analysis of a nearest neighbor algorithm.\\n\\nLangley’s (1993) analysis assumes a conjunctive target concept, noise-free boolean\\n\\nattributes, and a uniform distribution over the instance space. These assumptions do not\\n\\noverlap with the assumptions made here, which makes the two analyses highly comple-\\n\\nmentary. A worthwhile project for the future would be to integrate the two analyses in a\\n\\nsingle framework.\\n\\n7  Future Work\\nThe weak point of this theoretical model of cross-validation error is the assumption that\\n\\nthe inputs X are the same in the training set  and the testing set . The reason\\n\\nfor making this assumption is that it simplifies the mathematics. If the inputs in the\\n\\ntraining set were different from the inputs in the testing set, then we would need to make\\n\\nsome assumptions about f before we could prove any interesting results. When the inputs\\n\\nare the same in the training and testing sets, we can prove some interesting results about\\n\\ncross-validation error, without making any assumptions about the deterministic\\n\\nm1 E et( ) 0=\\n\\nmk m1 mk m1\\n\\nk 1=\\n\\nm1\\n\\nmk k 1>\\n\\nri ρi ti τi\\n\\nX y1( , ) X y2( , )\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 39\\n\\ncomponent f of the black box.\\n\\nThe main implication of the assumption, that X is the same in the training set and the\\n\\ntesting set, is that we may be underestimating the cross-validation error. We can expect a\\n\\nmodel to have more difficulty with prediction when the inputs in the testing set are\\n\\ndifferent from the inputs in the training set. Theorem 1 shows that the assumption is rea-\\n\\nsonable for large n, but we would like to know what happens when n is small. When a\\n\\nlearning algorithm makes predictions for inputs in the testing set that do not appear in the\\n\\ntraining set, the algorithm is performing interpolation or extrapolation. Future work\\n\\nshould extend the theory of cross-validation error to cover interpolation and extrapolation.\\n\\nAnother area for future work is proving that instance-based learning satisfies the\\n\\nassumptions of Theorem 3. It is conjectured that Theorem 3 is true for instance-based\\n\\nlearning, or that it is true under certain weak conditions. However, there is not yet a proof\\n\\nfor this.\\n\\nFinally, it would be interesting to apply the general theory of cross-validation error to\\n\\nsome other learning algorithms, such as ID3. Even when analytical results are not feasible,\\n\\nit is possible to use Monte Carlo techniques to evaluate the stability of learning algo-\\n\\nrithms. A Monte Carlo approach may also be required to evaluate the stability of some of\\n\\nthe more elaborate instance-based learning or memory-based reasoning algorithms. The\\n\\ncomplexity of some of these algorithms makes a formal analysis difficult.\\n\\n8  Conclusion\\nThis paper introduces a general theory of cross-validation error for algorithms that predict\\n\\nboolean-valued attributes. It shows that cross-validation error has two components,\\n\\naccuracy and stability. The optimal cross-validation error is derived and it is shown that\\n\\nalgorithms that maximize accuracy will give sub-optimal cross-validation error.\\n\\nThe theory was then applied to an analysis of voting in instance-based learning. It was\\n\\nproven that single nearest neighbor algorithms are unstable, because they maximize\\n\\naccuracy. The motivation for voting is to increase stability. In the best case, voting does\\n\\nindeed increase stability. However, in the worst case, voting can actually decrease\\n\\nstability. Techniques were provided for estimating the expected cross-validation error.\\n\\nThese techniques can be used to find the best values for k (the size of the neighborhood)\\n\\nand t (the threshold for voting).\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 40\\n\\nAcknowledgments\\n\\nI would like to thank Dr. David Aha for extensive, helpful comments on this paper. I\\n\\nwould also like to thank Professor Malcolm Forster for pointing out the relation between\\n\\nmy work and Akaike Information Criterion statistics.\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 41\\n\\nNotes\\n\\n1. The work described here does not rely on any of the results in Turney (1993). How-\\n\\never, to avoid duplication, some relevant issues that are discussed in Turney (1993) are\\n\\nnot discussed here (and vice versa). Therefore, although the work here stands on its\\n\\nown, the interested reader may wish to also read Turney (1993).\\n\\n2. Weiss and Kulikowski (1991) reserve the term “cross-validation” for N-fold cross-val-\\n\\nidation. In N-fold cross-validation, the data set is split into N subsets of roughly equal\\n\\nsize. The classification algorithm is then tested N times, each time training with\\n\\nof the subsets and testing with the remaining subset. Therefore N-fold cross-validation\\n\\nis essentially N applications of what is called “cross-validation” here. The essential\\n\\nconcepts remain the same whether the process is done once or N times.\\n\\n3. It is a common practice in statistics to prove theorems that hold asymptotically, as the\\n\\nsize of the data set increases to infinity. For example, Cover and Hart (1967) prove\\n\\nasymptotic theorems. Informally, we may say that asymptotic theorems assume an\\n\\ninfinite-sized data set. The first assumption here, that the inputs are the same in the\\n\\ntesting and training sets, is closely related to the assumption that the data sets are infi-\\n\\nnitely large. This is the point of Theorem 1 and Lemma 1. However, assumption 1 may\\n\\nbe satisfied by small, finite sets of data, when the data are generated by a planned, con-\\n\\ntrolled series of experiments. Thus assumption 1 is weaker than the assumption of infi-\\n\\nnite data sets.\\n\\nN 1−\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 42\\n\\nReferences\\n\\nAha, D.W., Kibler, D., & Albert, M.K. (1991) Instance-based learning algorithms,\\nMachine Learning, 6:37-66.\\n\\nCover, T.M., & Hart, P.E. (1967) Nearest neighbor pattern classification, IEEE Transac-\\ntions on Information Theory, IT-13:21-27. Also in (Dasarathy, 1991).\\n\\nDasarathy, B.V. (1991) Nearest Neighbor Pattern Classification Techniques, Edited col-\\nlection (California: IEEE Press).\\n\\nFix, E., & Hodges, J.L. (1951) Discriminatory analysis: nonparametric discrimination:\\nconsistency properties, Project 21-49-004, Report Number 4, USAF School of\\nAviation Medicine, Randolph Field, Texas, 261-279. Also in (Dasarathy, 1991).\\n\\nFraser, D.A.S. (1976) Probability and Statistics: Theory and Applications (Massachusetts:\\nDuxbury Press).\\n\\nKibler, D., Aha, D.W., & Albert, M.K. (1989) Instance-based prediction of real-valued\\nattributes, Computational Intelligence, 5:51-57.\\n\\nLangley, P. (1993) Average-case analysis of a nearest neighbor algorithm, Proceedings of\\nthe Thirteenth International Joint Conference on Artificial Intelligence, Chambéry,\\nFrance, in press.\\n\\nSakamoto, Y., Ishiguro, M., & Kitagawa, G. (1986) Akaike Information Criterion Statis-\\ntics (Dordrecht, Holland: Kluwer Academic Publishers).\\n\\nTomek, I. (1976) A generalization of the k-NN rule, IEEE Transactions on Systems, Man,\\nand Cybernetics, SMC-6:121-126. Also in (Dasarathy, 1991).\\n\\nTurney, P.D. (1990) The curve fitting problem: a solution, British Journal for the Philoso-\\nphy of Science, 41:509-530.\\n\\nTurney, P.D. (1993) A theory of cross-validation error. Submitted to the Journal of Exper-\\nimental and Theoretical Artificial Intelligence.\\n\\nWeiss, S.M., & Kulikowski, C.A. (1991) Computer Systems that Learn: Classification and\\nPrediction Methods from Statistics, Neural Nets, Machine Learning, and Expert\\nSystems (California: Morgan Kaufmann).\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 43\\n\\nAppendix: List of Symbols\\n\\nNote: Symbols that only occur in one theorem are omitted from this list.\\n\\nthe exclusive-or operator\\n\\nthe length of a vector\\n\\nthe mean of a probability distribution\\n\\nthe frequency with which f takes the value 1 in\\n\\nthe standard deviation of a probability distribution\\n\\nthe variance of a probability distribution\\n\\nthe value of the threshold  at which voting becomes unstable\\n\\n for a particular neighborhood\\n\\nthe cross-validation error vector\\n\\nthe instability vector\\n\\nthe training set error vector\\n\\nthe expectation operator\\n\\na scalar function of the input vector ; the target concept\\n\\na vector function of the input matrix\\n\\nthe size of the neighborhood\\n\\nthe model’s prediction for , given data X and ; a scalar\\n\\nthe model’s prediction for , given the data X and ; a vector\\n\\nthe optimal model, assuming that f and p are known to the modeler\\n\\nthe model\\n\\nthe number of samples; the number of observations\\n\\n… …⊕\\n\\n…\\n\\nµ\\n\\nρi Nk vi( )\\n\\nσ\\n\\nσ2\\n\\nτ t\\n\\nτi τ Nk vi( )\\n\\nec\\n\\nes\\n\\net\\n\\nE …( )\\n\\nf v( ) v\\n\\nf X( ) X\\n\\nk\\n\\nm v X y,( ) f v( ) y\\n\\nm X X y,( ) f X( ) y\\n\\nmα\\n\\nmβ m X X yi,( ) yi=\\n\\nn\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 44\\n\\nthe set of the k nearest neighbors  to\\n\\nthe probability that a random boolean variable  has the value 1\\n\\nthe probability that  is 1, when  is treated as a random variable\\n\\nthe probability of error  for\\n\\nthe probability of error  for\\n\\nthe probability that the majority of  are 1\\n\\nthe number of inputs; the number of features\\n\\nan unbiased estimator for\\n\\nR  in the terminology of Cover and Hart (1967)\\n\\n in the terminology of Cover and Hart (1967)\\n\\nthe similarity measure; a scalar measure of similarity between vectors\\n\\na threshold for voting, where ; with majority voting,\\n\\nan unbiased estimator for\\n\\na vector of inputs; the attributes of an observation; features\\n\\nthe i-th row in ; the i-th input vector; the i-th observation\\n\\na matrix of inputs; rows are observations and columns are features\\n\\nthe output; the class variable\\n\\na random boolean variable; noise in the class variable\\n\\na vector of random boolean variables\\n\\nNk vi( ) v1 … vk, , vi\\n\\np z\\n\\np' f v( ) f v( )\\n\\npα E ec( ) n⁄ mα\\n\\npβ E ec( ) n⁄ mβ\\n\\nPk y1 1, … y1 k,, ,\\n\\nr\\n\\nri ρi\\n\\npβ\\n\\nR* pα\\n\\nsim … …,( )\\n\\nt 0 t 1< < t 0.5=\\n\\nti τi\\n\\nv x1 … xr=\\n\\nvi X\\n\\nX\\n\\ny\\n\\nz y\\n\\nz\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 45\\n\\nFigures\\n\\nFigure 1. Plot of as a function of p.\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nmα\\n\\nmβ\\n\\np — probability of noise\\n\\nE\\ne c\\n\\n(\\n)\\n\\nn⁄\\n\\n—\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\ncr\\nos\\n\\ns-\\nva\\n\\nlid\\nat\\n\\nio\\nn \\n\\ner\\nro\\n\\nr\\n\\nE ec( ) n⁄\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 46\\n\\nFigure 2. A plot of  as a function of p.\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm5\\n\\nm1\\n\\nm3\\n\\nm∞\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\np — probability of noise\\n\\nE es( ) n⁄\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 47\\n\\nFigure 3. A plot of  as a function of p.\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm5\\n\\nm1\\n\\nm3\\n\\nm∞\\n\\np — probability of noise\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\nE es( ) n⁄\\n\\n\\n\\nError and Voting Submitted to the Journal of Experimental and Theoretical Artificial Intelligence\\n\\nMay 13, 1993 48\\n\\nFigure 4. A plot of  as a function of p.\\n\\n0.0 0.2 0.4 0.6 0.8 1.0\\n\\n0.0\\n\\n0.2\\n\\n0.4\\n\\n0.6\\n\\nm1\\n\\nm3\\n\\np — probability of noise\\n\\n —\\n a\\n\\nve\\nra\\n\\nge\\n e\\n\\nxp\\nec\\n\\nte\\nd \\n\\nin\\nst\\n\\nab\\nili\\n\\nty\\nE\\n\\ne s\\n(\\n\\n)\\nn⁄\\n\\nE es( ) n⁄\\n\\n\\n\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contents[\"0212030v1.pdf\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents/samples\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/search-get-started-python\n",
    "\n",
    "https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-AI-Enrichment/PythonTutorial-AzureSearch-AIEnrichment.ipynb\n",
    "\n",
    "https://benalexkeen.com/searching-document-text-at-scale-using-azure-cognitive-search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ff083f0c83558f9261023d47a77b9b3eb892c62cdbe066d046abcad1a5edb5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
