{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Enrichment to Azure Cognitive Search\n",
    "\n",
    "In this Jupyter Notebook, we create and run enrichment steps to unlock searchable content in the specified Azure blob. It performs operations over mixed content in Azure Storage, such as images and application files, using a skillset that analyzes and extracts text information that becomes searchable in Azure Cognitive Search. \n",
    "The reference sample can be found at [Tutorial: Use Python and AI to generate searchable content from Azure blobs](https://docs.microsoft.com/azure/search/cognitive-search-tutorial-blob-python).\n",
    "\n",
    "Although only  PDF files are used here, this can be done at a much larger scale and Azure Cognitive Search supports a range of other file formats including: Microsoft Office (DOCX/DOC, XSLX/XLS, PPTX/PPT, MSG), HTML, XML, ZIP, and plain text files (including JSON).\n",
    "\n",
    "This notebook creates the following objects on your search service:\n",
    "\n",
    "+ search index\n",
    "+ data source\n",
    "+ skillset\n",
    "+ indexer\n",
    "\n",
    "In the last step, you'll run queries against the search index to explore the text output that was generated for each blob.\n",
    "\n",
    "This notebook calls the [Search REST APIs](https://docs.microsoft.com/rest/api/searchservice/), but you can also use the Azure.Search.Documents client library in the Azure SDK for Python to perform the same steps. See this [Python quickstart](https://docs.microsoft.com/azure/search/search-get-started-python) for details.\n",
    "\n",
    "To run this notebook, you should have already uploade the sample data to a blob container in Azure Storage account. Replace the placeholders for the search service endpoint, the admin API key, Azure Storage connection string, and blob container. Once you've provided all four values, you can run all cells, but the query won't return results until the indexer is finished and the search index is loaded. \n",
    "\n",
    "We recommend running each step and making sure it completes before moving on.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-tutorial-blob\n",
    "\n",
    "https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-AI-Enrichment/PythonTutorial-AzureSearch-AIEnrichment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Accounts and Keys\n",
    "\n",
    "api_version = '2021-04-30-Preview'\n",
    "datasourceConnectionString = \"DefaultEndpointsProtocol=https;AccountName=arxivdatasetcs;AccountKey=M0f/46RGw1IvIpSEXuR7hyprzwvVBiCvIbKYNIlbtJzD2X96KBegKZp59pg4soiu2hSjtRXfhl/5+AStsWkLPA==;EndpointSuffix=core.windows.net\"\n",
    "\n",
    "# endpoint = os.environ.get(\"SEARCH_ENDPOINT\")\n",
    "# api_key = os.getenv(\"SEARCH_KEY\")\n",
    "# datasourceConnectionString = os.getenv(\"DATASOURCE_CONNECTION_STRING\")\n",
    "# cog_services_name = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_NAME\")\n",
    "# cog_services_key = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_KEY\")\n",
    "\n",
    "endpoint = \"https://azure-cog-search-pabdyosydd7ta.search.windows.net\"\n",
    "api_key = \"DDDUwtXOCSOjm1fPBRLNFofKEEvxXDpGF0Sy4S3ktjAzSeAgbz9Q\"\n",
    "cog_services_name = \"cognitive-service-pabdyosydd7ta\"\n",
    "cog_services_key = \"54c7c95ed3a74e2da7694dbd995a093c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names for the data source, skillset, index and indexer\n",
    "datasource_name = \"cogsrch-datasource\"\n",
    "skillset_name = \"cogsrch-skillset\"\n",
    "index_name = \"cogsrch-index\"\n",
    "indexer_name = \"cogsrch-indexer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "api_version = '2021-04-30-Preview'\n",
    "headers = {'Content-Type': 'application/json','api-key': api_key}\n",
    "params = {'api-version': api_version}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Source (Blob container with the Arxiv CS pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a data source\n",
    "# This data source points to your Azure Storage account.\n",
    "# You should already have a blob container that contains the sample data\n",
    "\n",
    "datasource_payload = {\n",
    "    \"name\": datasource_name,\n",
    "    \"description\": \"Demo files to demonstrate cognitive search capabilities.\",\n",
    "    \"type\": \"azureblob\",\n",
    "    \"credentials\": {\n",
    "        \"connectionString\": datasourceConnectionString\n",
    "    },\n",
    "    \"container\": {\n",
    "        \"name\": \"pdf\"\n",
    "    }\n",
    "}\n",
    "r = requests.put(endpoint + \"/datasources/\" + datasource_name,\n",
    "                 data=json.dumps(datasource_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Skillset - OCR, Text Splitter, Language Detection, KeyPhrase extraction, Entity Recognition\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-working-with-skillsets\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset\n",
    "skillset_payload = {\n",
    "    \"name\": skillset_name,\n",
    "    \"description\": \"Extract entities, detect language and extract key-phrases\",\n",
    "    \"skills\":\n",
    "    [\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Vision.OcrSkill\",\n",
    "            \"description\": \"Extract text (plain and structured) from image.\",\n",
    "            \"context\": \"/document/normalized_images/*\",\n",
    "            \"defaultLanguageCode\": \"en\",\n",
    "            \"detectOrientation\": True,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"image\",\n",
    "                  \"source\": \"/document/normalized_images/*\"\n",
    "                }\n",
    "            ],\n",
    "                \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\",\n",
    "                  \"targetName\" : \"images_text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.MergeSkill\",\n",
    "            \"description\": \"Create merged_text, which includes all the textual representation of each image inserted at the right location in the content field. This is useful for PDF and other file formats that supported embedded images.\",\n",
    "            \"context\": \"/document\",\n",
    "            \"insertPreTag\": \" \",\n",
    "            \"insertPostTag\": \" \",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\":\"text\", \"source\": \"/document/content\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"itemsToInsert\", \"source\": \"/document/normalized_images/*/images_text\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\":\"offsets\", \"source\": \"/document/normalized_images/*/contentOffset\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"mergedText\", \n",
    "                  \"targetName\" : \"merged_text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"textSplitMode\": \"pages\",\n",
    "            \"maximumPageLength\": 2000,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\",\n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"textItems\",\n",
    "                    \"targetName\": \"pages\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.LanguageDetectionSkill\",\n",
    "            \"description\": \"If you have multilingual content, adding a language code is useful for filtering\",\n",
    "            \"context\": \"/document\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\",\n",
    "                  \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"languageName\",\n",
    "                  \"targetName\": \"language\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.KeyPhraseExtractionSkill\",\n",
    "            \"context\": \"/document/pages/*\",\n",
    "            \"maxKeyPhraseCount\": 2,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/pages/*\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"keyPhrases\",\n",
    "                    \"targetName\": \"keyPhrases\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.V3.EntityRecognitionSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"categories\": [\"Person\", \"Location\", \"Organization\", \"DateTime\", \"URL\", \"Email\"],\n",
    "            \"minimumPrecision\": 0.3, \n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"persons\", \n",
    "                    \"targetName\": \"persons\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"locations\", \n",
    "                    \"targetName\": \"locations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"organizations\", \n",
    "                    \"targetName\": \"organizations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"dateTimes\", \n",
    "                    \"targetName\": \"dateTimes\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"urls\", \n",
    "                    \"targetName\": \"urls\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"emails\", \n",
    "                    \"targetName\": \"emails\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"cognitiveServices\": {\n",
    "        \"@odata.type\": \"#Microsoft.Azure.Search.CognitiveServicesByKey\",\n",
    "        \"description\": cog_services_name,\n",
    "        \"key\": cog_services_key\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/skillsets/\" + skillset_name,\n",
    "                 data=json.dumps(skillset_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the request defines the schema of the search index. A fields collection requires one field to be designated as the key. For blob content, this field is often the \"metadata_storage_path\" that uniquely identifies each blob in the container.\n",
    "\n",
    "In this schema, the \"text\" field receives OCR output, \"content\" receives merged output, \"language\" receives language detection output. Key phrases, entities, and several fields lifted from blob storage comprise the remaining entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "# Queries operate over the searchable fields and filterable fields in the index\n",
    "index_payload = {\n",
    "    \"name\": index_name,\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"pages\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"images_text\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"language\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"true\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"keyPhrases\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"persons\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"locations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"organizations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dateTimes\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"urls\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"emails\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_name\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_path\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"id\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": \"true\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        }\n",
    "    ],\n",
    "    \"semantic\": {\n",
    "      \"configurations\": [\n",
    "        {\n",
    "          \"name\": \"my-semantic-config\",\n",
    "          \"prioritizedFields\": {\n",
    "            \"prioritizedContentFields\": [\n",
    "                {\n",
    "                    \"fieldName\": \"content\"\n",
    "                }\n",
    "                ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexes/\" + index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run the Indexer - (runs the pipeline)\n",
    "This process takes about 30 mins to load all the Arxiv CS pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Create Indexer to drive the pipeline. The three components you have created thus far (data source, skillset, index) are inputs to an indexer. Creating the indexer on Azure Cognitive Search is the event that puts the entire pipeline into motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer\n",
    "indexer_payload = {\n",
    "    \"name\": indexer_name,\n",
    "    \"dataSourceName\": datasource_name,\n",
    "    \"targetIndexName\": index_name,\n",
    "    \"skillsetName\": skillset_name,\n",
    "    \"schedule\" : { \"interval\" : \"PT12H\"},\n",
    "    \"fieldMappings\": [\n",
    "        {\n",
    "          \"sourceFieldName\" : \"metadata_storage_path\",\n",
    "          \"targetFieldName\" : \"id\",\n",
    "          \"mappingFunction\" : { \"name\" : \"base64Encode\" }\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"metadata_storage_path\",\n",
    "          \"targetFieldName\" : \"metadata_storage_path\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"metadata_storage_name\",\n",
    "            \"targetFieldName\": \"metadata_storage_name\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputFieldMappings\":\n",
    "    [\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/merged_text\",\n",
    "            \"targetFieldName\": \"content\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/pages/*\",\n",
    "            \"targetFieldName\": \"pages\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\" : \"/document/normalized_images/*/images_text\",\n",
    "            \"targetFieldName\" : \"images_text\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/language\",\n",
    "            \"targetFieldName\": \"language\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/pages/*/keyPhrases/*\",\n",
    "            \"targetFieldName\": \"keyPhrases\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/persons\", \n",
    "          \"targetFieldName\" : \"persons\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/locations\", \n",
    "          \"targetFieldName\" : \"locations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/organizations\",\n",
    "            \"targetFieldName\": \"organizations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/dateTimes\",\n",
    "            \"targetFieldName\": \"dateTimes\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/urls\",\n",
    "            \"targetFieldName\": \"urls\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/emails\",\n",
    "            \"targetFieldName\": \"emails\"\n",
    "        }\n",
    "    ],\n",
    "    \"parameters\":\n",
    "    {\n",
    "        \"maxFailedItems\": -1,\n",
    "        \"maxFailedItemsPerBatch\": -1,\n",
    "        \"configuration\":\n",
    "        {\n",
    "            \"dataToExtract\": \"contentAndMetadata\",\n",
    "            \"imageAction\": \"generateNormalizedImages\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexers/\" + indexer_name,\n",
    "                 data=json.dumps(indexer_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Status: inProgress\n",
      "Items Processed: 1700\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Optionally, get indexer status to confirm that it's running\n",
    "r = requests.get(endpoint + \"/indexers/\" + indexer_name +\n",
    "                 \"/status\", headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))\n",
    "print(r.status_code)\n",
    "print(\"Status:\",r.json().get('lastResult').get('status'))\n",
    "print(\"Items Processed:\",r.json().get('lastResult').get('itemsProcessed'))\n",
    "print(r.ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents/samples\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/search-get-started-python\n",
    "\n",
    "https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-AI-Enrichment/PythonTutorial-AzureSearch-AIEnrichment.ipynb\n",
    "\n",
    "https://benalexkeen.com/searching-document-text-at-scale-using-azure-cognitive-search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ff083f0c83558f9261023d47a77b9b3eb892c62cdbe066d046abcad1a5edb5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
