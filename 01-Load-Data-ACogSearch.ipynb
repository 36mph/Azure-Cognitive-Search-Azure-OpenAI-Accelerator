{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Enrichment to Azure Cognitive Search\n",
    "\n",
    "In this Jupyter Notebook, we create and run enrichment steps to unlock searchable content in the specified Azure blob. It performs operations over mixed content in Azure Storage, such as images and application files, using a skillset that analyzes and extracts text information that becomes searchable in Azure Cognitive Search. \n",
    "The reference sample can be found at [Tutorial: Use Python and AI to generate searchable content from Azure blobs](https://docs.microsoft.com/azure/search/cognitive-search-tutorial-blob-python).\n",
    "\n",
    "Although only  PDF files are used here, this can be done at a much larger scale and Azure Cognitive Search supports a range of other file formats including: Microsoft Office (DOCX/DOC, XSLX/XLS, PPTX/PPT, MSG), HTML, XML, ZIP, and plain text files (including JSON).\n",
    "\n",
    "This notebook creates the following objects on your search service:\n",
    "\n",
    "+ search index\n",
    "+ data source\n",
    "+ skillset\n",
    "+ indexer\n",
    "\n",
    "In the last step, you'll run queries against the search index to explore the text output that was generated for each blob.\n",
    "\n",
    "This notebook calls the [Search REST APIs](https://docs.microsoft.com/rest/api/searchservice/), but you can also use the Azure.Search.Documents client library in the Azure SDK for Python to perform the same steps. See this [Python quickstart](https://docs.microsoft.com/azure/search/search-get-started-python) for details.\n",
    "\n",
    "To run this notebook, you should have already uploade the sample data to a blob container in Azure Storage account. Replace the placeholders for the search service endpoint, the admin API key, Azure Storage connection string, and blob container. Once you've provided all four values, you can run all cells, but the query won't return results until the indexer is finished and the search index is loaded. \n",
    "\n",
    "We recommend running each step and making sure it completes before moving on.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-tutorial-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Accounts and Keys\n",
    "\n",
    "api_version = '2021-04-30-Preview'\n",
    "\n",
    "# endpoint = os.environ.get(\"SEARCH_ENDPOINT\")\n",
    "# api_key = os.getenv(\"SEARCH_KEY\")\n",
    "# datasourceConnectionString = os.getenv(\"DATASOURCE_CONNECTION_STRING\")\n",
    "# cog_services_name = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_NAME\")\n",
    "# cog_services_key = os.getenv(\"COGNITIVE_SERVICES_ACCOUNT_KEY\")\n",
    "\n",
    "endpoint = \"https://azure-cog-search-pabdyosydd7ta.search.windows.net\"\n",
    "api_key = \"DDDUwtXOCSOjm1fPBRLNFofKEEvxXDpGF0Sy4S3ktjAzSeAgbz9Q\"\n",
    "datasourceConnectionString = \"DefaultEndpointsProtocol=https;AccountName=arxivdatasetcs;AccountKey=M0f/46RGw1IvIpSEXuR7hyprzwvVBiCvIbKYNIlbtJzD2X96KBegKZp59pg4soiu2hSjtRXfhl/5+AStsWkLPA==;EndpointSuffix=core.windows.net\"\n",
    "cog_services_name = \"cognitive-service-pabdyosydd7ta\"\n",
    "cog_services_key = \"54c7c95ed3a74e2da7694dbd995a093c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the names for the data source, skillset, index and indexer\n",
    "datasource_name = \"cogsrch-datasource\"\n",
    "skillset_name = \"cogsrch-skillset\"\n",
    "index_name = \"cogsrch-index\"\n",
    "indexer_name = \"cogsrch-indexer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "api_version = '2021-04-30-Preview'\n",
    "headers = {'Content-Type': 'application/json','api-key': api_key}\n",
    "params = {'api-version': api_version}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Source (Blob container with the Arxiv CS pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a data source\n",
    "# This data source points to your Azure Storage account.\n",
    "# You should already have a blob container that contains the sample data\n",
    "\n",
    "datasource_payload = {\n",
    "    \"name\": datasource_name,\n",
    "    \"description\": \"Demo files to demonstrate cognitive search capabilities.\",\n",
    "    \"type\": \"azureblob\",\n",
    "    \"credentials\": {\n",
    "        \"connectionString\": datasourceConnectionString\n",
    "    },\n",
    "    \"container\": {\n",
    "        \"name\": \"pdf\"\n",
    "    }\n",
    "}\n",
    "r = requests.put(endpoint + \"/datasources/\" + datasource_name,\n",
    "                 data=json.dumps(datasource_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Skillset - OCR, Text Splitter, Language Detection, KeyPhrase extraction, Entity Recognition\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-working-with-skillsets\n",
    "\n",
    "https://learn.microsoft.com/en-us/azure/search/cognitive-search-predefined-skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create a skillset\n",
    "skillset_payload = {\n",
    "    \"name\": skillset_name,\n",
    "    \"description\": \"Extract entities, detect language and extract key-phrases\",\n",
    "    \"skills\":\n",
    "    [\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Vision.OcrSkill\",\n",
    "            \"description\": \"Extract text (plain and structured) from image.\",\n",
    "            \"context\": \"/document/normalized_images/*\",\n",
    "            \"defaultLanguageCode\": \"en\",\n",
    "            \"detectOrientation\": True,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"image\",\n",
    "                  \"source\": \"/document/normalized_images/*\"\n",
    "                }\n",
    "            ],\n",
    "                \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.MergeSkill\",\n",
    "            \"description\": \"Create merged_text, which includes all the textual representation of each image inserted at the right location in the content field. This is useful for PDF and other file formats that supported embedded images.\",\n",
    "            \"context\": \"/document\",\n",
    "            \"insertPreTag\": \" \",\n",
    "            \"insertPostTag\": \" \",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\":\"text\", \"source\": \"/document/content\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"itemsToInsert\", \"source\": \"/document/normalized_images/*/text\"\n",
    "                },\n",
    "                {\n",
    "                  \"name\":\"offsets\", \"source\": \"/document/normalized_images/*/contentOffset\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"mergedText\", \n",
    "                  \"targetName\" : \"merged_text\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"textSplitMode\": \"pages\",\n",
    "            \"maximumPageLength\": 4000,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\",\n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"textItems\",\n",
    "                    \"targetName\": \"pages\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.LanguageDetectionSkill\",\n",
    "            \"description\": \"If you have multilingual content, adding a language code is useful for filtering\",\n",
    "            \"context\": \"/document\",\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                  \"name\": \"text\",\n",
    "                  \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                  \"name\": \"languageName\",\n",
    "                  \"targetName\": \"language\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.KeyPhraseExtractionSkill\",\n",
    "            \"context\": \"/document/pages/*\",\n",
    "            \"maxKeyPhraseCount\": 2,\n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/pages/*\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"keyPhrases\",\n",
    "                    \"targetName\": \"keyPhrases\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"@odata.type\": \"#Microsoft.Skills.Text.V3.EntityRecognitionSkill\",\n",
    "            \"context\": \"/document\",\n",
    "            \"categories\": [\"Person\", \"Location\", \"Organization\", \"DateTime\", \"URL\", \"Email\"],\n",
    "            \"minimumPrecision\": 0.3, \n",
    "            \"inputs\": [\n",
    "                {\n",
    "                    \"name\": \"text\", \n",
    "                    \"source\": \"/document/merged_text\"\n",
    "                }\n",
    "            ],\n",
    "            \"outputs\": [\n",
    "                {\n",
    "                    \"name\": \"persons\", \n",
    "                    \"targetName\": \"persons\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"locations\", \n",
    "                    \"targetName\": \"locations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"organizations\", \n",
    "                    \"targetName\": \"organizations\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"dateTimes\", \n",
    "                    \"targetName\": \"dateTimes\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"urls\", \n",
    "                    \"targetName\": \"urls\"\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"emails\", \n",
    "                    \"targetName\": \"emails\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"cognitiveServices\": {\n",
    "        \"@odata.type\": \"#Microsoft.Azure.Search.CognitiveServicesByKey\",\n",
    "        \"description\": cog_services_name,\n",
    "        \"key\": cog_services_key\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/skillsets/\" + skillset_name,\n",
    "                 data=json.dumps(skillset_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The body of the request defines the schema of the search index. A fields collection requires one field to be designated as the key. For blob content, this field is often the \"metadata_storage_path\" that uniquely identifies each blob in the container.\n",
    "\n",
    "In this schema, the \"text\" field receives OCR output, \"content\" receives merged output, \"language\" receives language detection output. Key phrases, entities, and several fields lifted from blob storage comprise the remaining entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an index\n",
    "# Queries operate over the searchable fields and filterable fields in the index\n",
    "index_payload = {\n",
    "    \"name\": index_name,\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"content\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"text\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"language\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"true\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"keyPhrases\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"persons\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"locations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"organizations\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"dateTimes\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"urls\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"emails\",\n",
    "            \"type\": \"Collection(Edm.String)\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"true\",\n",
    "            \"facetable\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_path\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"key\": \"true\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"metadata_storage_name\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": \"true\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "            }\n",
    "    ],\n",
    "    \"semantic\": {\n",
    "      \"configurations\": [\n",
    "        {\n",
    "          \"name\": \"my-semantic-config\",\n",
    "          \"prioritizedFields\": {\n",
    "            \"prioritizedContentFields\": [\n",
    "                {\n",
    "                    \"fieldName\": \"content\"\n",
    "                }\n",
    "                ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexes/\" + index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run the Indexer - (runs the pipeline)\n",
    "This process takes about 30 mins to load all the Arxiv CS pds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call Create Indexer to drive the pipeline. The three components you have created thus far (data source, skillset, index) are inputs to an indexer. Creating the indexer on Azure Cognitive Search is the event that puts the entire pipeline into motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer\n",
    "indexer_payload = {\n",
    "    \"name\": indexer_name,\n",
    "    \"dataSourceName\": datasource_name,\n",
    "    \"targetIndexName\": index_name,\n",
    "    \"skillsetName\": skillset_name,\n",
    "    \"fieldMappings\": [\n",
    "        {\n",
    "          \"sourceFieldName\" : \"metadata_storage_path\",\n",
    "          \"targetFieldName\" : \"metadata_storage_path\",\n",
    "          \"mappingFunction\" : { \"name\" : \"base64Encode\" }\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"metadata_storage_name\",\n",
    "            \"targetFieldName\": \"metadata_storage_name\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputFieldMappings\":\n",
    "    [\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/merged_text\",\n",
    "            \"targetFieldName\": \"content\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\" : \"/document/normalized_images/*/text\",\n",
    "            \"targetFieldName\" : \"text\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/language\",\n",
    "            \"targetFieldName\": \"language\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/pages/*/keyPhrases/*\",\n",
    "            \"targetFieldName\": \"keyPhrases\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/persons\", \n",
    "          \"targetFieldName\" : \"persons\"\n",
    "        },\n",
    "        {\n",
    "          \"sourceFieldName\" : \"/document/locations\", \n",
    "          \"targetFieldName\" : \"locations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/organizations\",\n",
    "            \"targetFieldName\": \"organizations\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/dateTimes\",\n",
    "            \"targetFieldName\": \"dateTimes\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/urls\",\n",
    "            \"targetFieldName\": \"urls\"\n",
    "        },\n",
    "        {\n",
    "            \"sourceFieldName\": \"/document/emails\",\n",
    "            \"targetFieldName\": \"emails\"\n",
    "        }\n",
    "    ],\n",
    "    \"parameters\":\n",
    "    {\n",
    "        \"maxFailedItems\": -1,\n",
    "        \"maxFailedItemsPerBatch\": -1,\n",
    "        \"configuration\":\n",
    "        {\n",
    "            \"dataToExtract\": \"contentAndMetadata\",\n",
    "            \"imageAction\": \"generateNormalizedImages\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "r = requests.put(endpoint + \"/indexers/\" + indexer_name,\n",
    "                 data=json.dumps(indexer_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "Status: success\n",
      "Items Processed: 9887\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Optionally, get indexer status to confirm that it's running\n",
    "r = requests.get(endpoint + \"/indexers/\" + indexer_name +\n",
    "                 \"/status\", headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))\n",
    "print(r.status_code)\n",
    "print(\"Status:\",r.json().get('lastResult').get('status'))\n",
    "print(\"Items Processed:\",r.json().get('lastResult').get('itemsProcessed'))\n",
    "print(r.ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the service for the index definition\n",
    "# Query responses can be verbose. If you get \"Output exceeds the size limit. Open the full output data in a text editor\", open the output in an editor.\n",
    "# r = requests.get(endpoint + \"/indexes/\" + index_name,\n",
    "#                  headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the index to return the contents of \"organizations\", created through Entity Recognition during enrichment\n",
    "# For keyword search, replace the asterisk with comma-separated query terms: search=microsoft,azure\n",
    "# r = requests.get(endpoint + \"/indexes/\" + index_name +\n",
    "#                  \"/docs?&search=*&$select=organizations\", headers=headers, params=params)\n",
    "# pprint(json.dumps(r.json(), indent=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-pabdyosydd7ta.search.windows.net/indexes/cogsrch-index/docs?api-version=2021-04-30-Preview&search=what is artificial intelligence&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-true&highlight=content&select=content&highlightPreTag=%3Cspan%20style%3D%22background-color%3A%20%23f5e8a3%22%3E&highlightPostTag=%3C%2Fspan%3E\n",
      "200\n",
      "Results Found: 9795, Results Returned: 5\n",
      "Highest Search Score: 16.74226\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "url = endpoint + '/indexes/'+ index_name + '/docs'\n",
    "url += '?api-version={}'.format(api_version)\n",
    "url += '&search=what is artificial intelligence'\n",
    "url += '&$top=5'\n",
    "url += '&queryLanguage=en-us'\n",
    "url += '&queryType=semantic'\n",
    "url += '&semanticConfiguration=my-semantic-config'\n",
    "url += '&$count=true'\n",
    "url += '&speller=lexicon'\n",
    "url += '&answers=extractive|count-3'\n",
    "url += '&captions=extractive|highlight-true'\n",
    "url += '&highlight=content'\n",
    "url += '&select=content'\n",
    "url += '&highlightPreTag=' + urllib.parse.quote('<span style=\"background-color: #f5e8a3\">', safe='')\n",
    "url += '&highlightPostTag=' + urllib.parse.quote('</span>', safe='')\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "print(url)\n",
    "print(resp.status_code)\n",
    "\n",
    "search_results = resp.json()\n",
    "print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))\n",
    "print(\"Highest Search Score: {}\".format(search_results['value'][0]['@search.score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i= 0\n",
    "# for r in search_results.items():\n",
    "#     pprint(r)\n",
    "#     i+=1\n",
    "#     if i==4: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Top Answers</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.97802734375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The science of Artificial Intelligence (AI) may be defined as the construction of intelligent systems and their analysis. A natural definition of a system is anything that has an input and an output stream. Intelligence is more complicated."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>Answer - score: 0.83349609375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "artificial intelligence     intelligence knowledge based expert systems, knowledge based expert systems or  simply, expert systems are a product of artificial intelligence [a.i], that branch of  computer science, which deals with development of programmes that exhibit intelligent  human behaviour to arrive at decisions in a complex environment …"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Top Results</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0701125v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.225250244140625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The science of Artificial Intelligence (AI) may be defined as the construction of intelligent systems and their analysis. A natural definition of a system is anything that has an input and an output stream. Intelligence is more complicated."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0607138v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 2.221771240234375</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The  main purpose of artificial intelligence is find a way of organizing knowledge in such a  way that helps decision making to take place rapidly and efficiently; which means that  learning should happen at optimal speed and in compact storage."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0511018v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.969390869140625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "artificial intelligence     intelligence knowledge based expert systems, knowledge based expert systems or  simply, expert systems are a product of artificial intelligence [a.i], that branch of  computer science, which deals with development of programmes that exhibit intelligent  human behaviour to arrive at decisions in a complex environment …"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0211039v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.90167236328125</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "some of the properties observed in the developed asm are: (1) the strong dependence of the observed external behaviour  in the internal states of the entity, (2) the action selection to the extern medium and to the internal medium, (3) the  stability in the action selection, (4) the persistence in the execution of an action, (5) the existence of …"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0211029v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 1.81646728515625</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Within computer sciences, the artificial intelligence area has constituted one of the main scenarios to model  biological systems. This fact responds to the great variety of models, techniques and methods that support this research area, many of which are inherited of disciplines such as psychology, cognitive sciences and neuroscience."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers from semantic Search\n",
    "display(HTML('<h3>Top Answers</h3>'))\n",
    "for result in search_results['@search.answers']:\n",
    "    if result['score'] > 0.5:\n",
    "        display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "        display(HTML(result['text']))\n",
    "\n",
    "# Results from semantic search\n",
    "\n",
    "contents = dict()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h3>Top Results</h3>'))\n",
    "for result in search_results['value']:\n",
    "    if result['@search.rerankerScore'] > 1:\n",
    "        display(HTML('<h5>' + result['metadata_storage_name'] + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: ' + str(result['@search.rerankerScore']) + '</h5>'))\n",
    "        for caption in result['@search.captions']:\n",
    "            # print(caption)\n",
    "            display(HTML(caption['text']))\n",
    "        contents[result['metadata_storage_name']]=result['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course we want OpenAI to give a better answer chat style, so we instead of sending this results, we send the content of this articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the 4096 tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "This is what the APP will do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Azure/azure-sdk-for-python/tree/main/sdk/search/azure-search-documents/samples\n",
    "\n",
    "https://github.com/Azure-Samples/azure-search-python-samples/blob/main/Tutorial-AI-Enrichment/PythonTutorial-AzureSearch-AIEnrichment.ipynb\n",
    "\n",
    "https://benalexkeen.com/searching-document-text-at-scale-using-azure-cognitive-search/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ff083f0c83558f9261023d47a77b9b3eb892c62cdbe066d046abcad1a5edb5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
