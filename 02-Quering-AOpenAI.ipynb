{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "Now that we have our Search Engine loaded and running, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from app.embeddings import OpenAIEmbeddings\n",
    "from app.prompts import STUFF_PROMPT, REFINE_PROMPT, REFINE_QUESTION_PROMPT\n",
    "from app.credentials import (\n",
    "    API_VERSION,\n",
    "    DATASOURCE_CONNECTION_STRING,\n",
    "    AZURE_SEARCH_ENDPOINT,\n",
    "    AZURE_SEARCH_KEY,\n",
    "    COG_SERVICES_NAME,\n",
    "    COG_SERVICES_KEY,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    AZURE_OPENAI_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': AZURE_SEARCH_KEY}\n",
    "params = {'api-version': API_VERSION}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Without Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a46e2d3-298a-4708-83de-9e108b1a117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index that we are going to query (from Notebook 01)\n",
    "index_name = \"cogsrch-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"create a bullet list the authors that talk about Gradient Boosting Machines\" # Notice that is misspelled intentionally\n",
    "\n",
    "# Try questions that you think might be answered or addressed in computer science papers in 2020-2021\n",
    "# And compare the results with the open version of ChatGPT\n",
    "# The idea is that the answers using Azure OpenAI only looks at the information contained on these publications.\n",
    "\n",
    "# For Example:\n",
    "# What is CLP?\n",
    "# How Markov chains work?\n",
    "# How "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f5c7e9f-42b9-4081-8975-648e4b31e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-bbuqqkw6y2eee.search.windows.net/indexes/cogsrch-index/docs?api-version=2021-04-30-Preview&search=create a bullet list the authors that talk about Gradient Boosting Machines&select=pages&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-true&highlightPreTag=%3Cspan%20style%3D%22background-color%3A%20%23f5e8a3%22%3E&highlightPostTag=%3C%2Fspan%3E\n",
      "200\n",
      "Results Found: 9857, Results Returned: 5\n"
     ]
    }
   ],
   "source": [
    "url = AZURE_SEARCH_ENDPOINT + '/indexes/'+ index_name + '/docs'\n",
    "url += '?api-version={}'.format(API_VERSION)\n",
    "url += '&search={}'.format(QUESTION)\n",
    "url += '&select=pages'\n",
    "url += '&$top=5'\n",
    "url += '&queryLanguage=en-us'\n",
    "url += '&queryType=semantic'\n",
    "url += '&semanticConfiguration=my-semantic-config'\n",
    "url += '&$count=true'\n",
    "url += '&speller=lexicon'\n",
    "url += '&answers=extractive|count-3'\n",
    "url += '&captions=extractive|highlight-true'\n",
    "url += '&highlightPreTag=' + urllib.parse.quote('<span style=\"background-color: #f5e8a3\">', safe='')\n",
    "url += '&highlightPostTag=' + urllib.parse.quote('</span>', safe='')\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "print(url)\n",
    "print(resp.status_code)\n",
    "\n",
    "search_results = resp.json()\n",
    "print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "015f0259-6609-4032-b8ae-09e95c69cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h5>0102015v1.pdf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: 0.4769554138183594</h5>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "[4] L. Mason, J. Baxter, P. Bartlett, M. Fran: Boosting Algorithms as Gradient Descent in Function Space prepreint, 1999. [5] I. Ekeland, R. Teman: Analyse convexe et probleÌ€mes variationnels Dunod Gauthier-Villard, Paris. [6] C. Baiocchi, A. Capelo: Disequazioni variazionali e quasivariazionali."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers from semantic Search\n",
    "display(HTML('<h4>Top Answers</h4>'))\n",
    "for result in search_results['@search.answers']:\n",
    "    if result['score'] > 0.5: # Show answers that are at least 50% of the max possible score=1\n",
    "        display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "        display(HTML(result['text']))\n",
    "\n",
    "        \n",
    "# Results from key-word search\n",
    "file_content = dict()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results</h4>'))\n",
    "for result in search_results['value']:\n",
    "    if result['@search.rerankerScore'] > 0.4: # Show results that are at least 10% of the max possible score=4\n",
    "        display(HTML('<h5>' + result['metadata_storage_name'] + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: ' + str(result['@search.rerankerScore']) + '</h5>'))\n",
    "        display(HTML(result['@search.captions'][0]['text']))\n",
    "        file_content[result['metadata_storage_path']]=result['pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "## Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic search feature of Azure Cognitive Search service is pretty good. It gives us the top answers and also the top results with the corresponding file and the paragraph where the answers is possible located\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "## Using Azure OpenAI\n",
    "\n",
    "Of course we want OpenAI to give a better answer chat style, so we instead of sending this results, we send the content of this articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the 4096 tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "Let's do that\n",
    "\n",
    "We will use a genius library call LangChain that wraps a lot of boiler plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Azure OpenAI create a deployment for the model \"text-embedding-ada-002\"\n",
    "# and VERY IMPORTANT name the deployment the same: \"text-embedding-ada-002\"\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key,value in file_content.items():\n",
    "    for page in value:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 ms, sys: 1.34 ms, total: 26.3 ms\n",
      "Wall time: 347 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(len(docs)>1):\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "else:\n",
    "    print(\"No results Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57429335-34d3-458a-b7c9-52482a0936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_db = db.similarity_search(QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c4788-715e-44dd-b2b8-3f1c3201e4e0",
   "metadata": {},
   "source": [
    "The default prompts used by Langchain for the chain_type=refine can be found here. We modified them a bit to include language and summarization\n",
    "\n",
    "https://github.com/hwchase17/langchain/blob/master/langchain/chains/qa_with_sources/refine_prompts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9f65e2f-8333-4f9f-adce-fe434019e243",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(deployment_name=\"text-davinci-003\", model_name=\"text-davinci-003\", temperature=0.5, max_tokens=500)\n",
    "chain = load_qa_chain(llm, chain_type=\"refine\", question_prompt=REFINE_QUESTION_PROMPT, refine_prompt=REFINE_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26a31887-0096-4c2b-94e3-4c4937920e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.6 ms, sys: 3.46 ms, total: 16 ms\n",
      "Wall time: 7.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRY CHANGING THE LANGUAGE\n",
    "\n",
    "response = chain({\"input_documents\": docs_db, \"question\": QUESTION, \"language\": \"English\"}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "addffeab-527e-407e-9949-3301cad6404c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Azure OpenAI Answer:</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "â€¢ J. Friedman: Greedy function approximation: a gradient boosting machine. Stanford University, Febbraio 1999. \n",
       "â€¢ J. Friedman: Stocastic Gradient Boosting. Stanford University, Marzo 1999. \n",
       "â€¢ L. Mason, J. Baxter, P. Bartlett, M. Fran: Boosting Algorithms as Gradient Descent in Function Space prepreint, 1999.\n",
       "â€¢ M. Visentin: Non-convex cost functionals in boosting algorithms and methods for panel selection.\n",
       "â€¢ J. Friedman and T. Hastie: Additive Logistic Regression: a Statistical View of Boosting. Annals of Statistics, 2000.\n",
       "â€¢ P. Bartlett and J. Baxter: Boosting Regression Models. Technical Report, 2000.\n",
       "â€¢ T. Hastie, R. Tibshirani and J. Friedman: The Elements of Statistical Learning, 2001."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Azure OpenAI Answer:</h4>'))\n",
    "display(HTML(response['output_text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Azure Cognitive Search give us the top results\n",
    "- Azure OpenAI construct takes this results and understand them to give the best answer\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5a404-923f-4139-9cce-3b8aeee163f0",
   "metadata": {},
   "source": [
    "# Difference of ChatGPT vs GPT Smart Search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4583036-95ab-43ed-a70f-1e96d83a079d",
   "metadata": {},
   "source": [
    "We are using the language power of GPT-3 trained models in OpenAI to understand our questions and to respond accordingly but only within the context of our data.\n",
    "Try for yourself asking the same question in ChatGPT vs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634f5bd8-0d56-47b8-84fd-fe9b678bfc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
