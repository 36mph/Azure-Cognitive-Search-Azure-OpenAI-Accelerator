{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d59d527f-1100-45ff-b051-5f7c9029d94d",
   "metadata": {},
   "source": [
    "# Queries with and without Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9a9444-dc90-4fc3-aea7-8ee918301aba",
   "metadata": {},
   "source": [
    "Now that we have our Search Engine loaded and running, we are going to try some example queries and then use Azure OpenAI service to see if we can get even better results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f6c7e3-9037-4b1e-ae17-1deaa27b9c08",
   "metadata": {},
   "source": [
    "## Set up variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e50b404-a061-49e7-a3c7-c6eabc98ff0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = '2021-04-30-Preview'\n",
    "\n",
    "# endpoint = os.environ.get(\"SEARCH_ENDPOINT\")\n",
    "# api_key = os.getenv(\"SEARCH_KEY\")\n",
    "\n",
    "endpoint = \"https://azure-cog-search-pabdyosydd7ta.search.windows.net\"\n",
    "api_key = \"DDDUwtXOCSOjm1fPBRLNFofKEEvxXDpGF0Sy4S3ktjAzSeAgbz9Q\"\n",
    "index_name = \"cogsrch-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2c22f8-79ab-405c-95e8-77a1978e53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Payloads header\n",
    "api_version = '2021-04-30-Preview'\n",
    "headers = {'Content-Type': 'application/json','api-key': api_key}\n",
    "params = {'api-version': api_version}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9297d29b-1f61-4dce-858e-bf4272172dba",
   "metadata": {},
   "source": [
    "## Without Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9b53c14-19bd-451f-aa43-7ad27ccfeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"what is pepsi\" # Notice that is misspelled intentionally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6f5c7e9f-42b9-4081-8975-648e4b31e175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://azure-cog-search-pabdyosydd7ta.search.windows.net/indexes/cogsrch-index/docs?api-version=2021-04-30-Preview&search=what is pepsi&select=pages&$top=5&queryLanguage=en-us&queryType=semantic&semanticConfiguration=my-semantic-config&$count=true&speller=lexicon&answers=extractive|count-3&captions=extractive|highlight-true&highlightPreTag=%3Cspan%20style%3D%22background-color%3A%20%23f5e8a3%22%3E&highlightPostTag=%3C%2Fspan%3E\n",
      "200\n",
      "Results Found: 6921, Results Returned: 5\n",
      "Highest Search Score: 15.681919\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "url = endpoint + '/indexes/'+ index_name + '/docs'\n",
    "url += '?api-version={}'.format(api_version)\n",
    "url += '&search={}'.format(QUESTION)\n",
    "url += '&select=pages'\n",
    "url += '&$top=5'\n",
    "url += '&queryLanguage=en-us'\n",
    "url += '&queryType=semantic'\n",
    "url += '&semanticConfiguration=my-semantic-config'\n",
    "url += '&$count=true'\n",
    "url += '&speller=lexicon'\n",
    "url += '&answers=extractive|count-3'\n",
    "url += '&captions=extractive|highlight-true'\n",
    "url += '&highlightPreTag=' + urllib.parse.quote('<span style=\"background-color: #f5e8a3\">', safe='')\n",
    "url += '&highlightPostTag=' + urllib.parse.quote('</span>', safe='')\n",
    "\n",
    "resp = requests.get(url, headers=headers)\n",
    "print(url)\n",
    "print(resp.status_code)\n",
    "\n",
    "search_results = resp.json()\n",
    "print(\"Results Found: {}, Results Returned: {}\".format(search_results['@odata.count'], len(search_results['value'])))\n",
    "print(\"Highest Search Score: {}\".format(search_results['value'][0]['@search.score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "015f0259-6609-4032-b8ae-09e95c69cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Top Answers (Semantic Search)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h4>Top Results (Key-Word Search)</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answers from semantic Search\n",
    "display(HTML('<h4>Top Answers (Semantic Search)</h4>'))\n",
    "for result in search_results['@search.answers']:\n",
    "    if result['score'] > 0.5:\n",
    "        display(HTML('<h5>' + 'Answer - score: ' + str(result['score']) + '</h5>'))\n",
    "        display(HTML(result['text']))\n",
    "\n",
    "        \n",
    "# Results from key-word search\n",
    "file_content = dict()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "display(HTML('<h4>Top Results (Key-Word Search)</h4>'))\n",
    "for result in search_results['value']:\n",
    "    if result['@search.rerankerScore'] > 0.3:\n",
    "        display(HTML('<h5>' + result['metadata_storage_name'] + '&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;score: ' + str(result['@search.rerankerScore']) + '</h5>'))\n",
    "        display(HTML(result['@search.captions'][0]['text']))\n",
    "        file_content[result['metadata_storage_path']]=result['pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d3e6-afb2-4fa7-96d3-69bc2373ded5",
   "metadata": {},
   "source": [
    "## Comments on Query results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e02227-6a92-4944-86f8-6c1e38d90fe4",
   "metadata": {},
   "source": [
    "As seen above the semantic search feature of Azure Cognitive Search service is pretty good. It gives us the top answers and also the top results with the corresponding file and the paragraph where the answers is possible located\n",
    "Let's see if we can make this better with Azure OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df3e6d4-9a09-4b0f-b328-238738ccfaec",
   "metadata": {},
   "source": [
    "## Using Azure OpenAI\n",
    "\n",
    "Of course we want OpenAI to give a better answer chat style, so we instead of sending this results, we send the content of this articles to OpenAI and lets GPT model give the answer.\n",
    "\n",
    "The problem is that the content of the search result files is or can be very lengthy, more than the 4096 tokens allowed by the GPT Azure OpenAI models. So what we need to do is to split in chunks, vectorize and do a vector semantic search. \n",
    "Let's do that\n",
    "\n",
    "We will use a genius library call LangChain that wraps a lot of boiler plate code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eea62a7d-7e0e-4a93-a89c-20c96560c665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from App.app.embeddings import OpenAIEmbeddings\n",
    "from App.app.prompts import STUFF_PROMPT\n",
    "from langchain.chains import VectorDBQAWithSourcesChain\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ[\"AZURE_OPENAI_API_KEY\"] = \"48e3114b81d1430eb1f3df7fb783f176\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://pablo.openai.azure.com/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a03f1f10-32b0-4c1e-8a0e-eee1b1d29ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(document_model_name='text-embedding-ada-002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8f7b41d2-65b0-4058-8a46-c76cf6960720",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for key,value in file_content.items():\n",
    "    for page in value:\n",
    "        docs.append(Document(page_content=page, metadata={\"source\": key}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3315033a-4a08-4db5-8f5c-fa0a99892dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results Found\n",
      "CPU times: user 0 ns, sys: 211 µs, total: 211 µs\n",
      "Wall time: 208 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if(len(docs)>1):\n",
    "    db = FAISS.from_documents(docs, embeddings)\n",
    "else:\n",
    "    print(\"No results Found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbafc5f6-b829-4792-a701-f83ea234c964",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = VectorDBQAWithSourcesChain.from_chain_type(AzureOpenAI(deployment_name=\"text-davinci-003\", model_name=\"text-davinci-003\", temperature=0),\n",
    "                                                   chain_type=\"stuff\", vectorstore=db,\n",
    "                                                   chain_type_kwargs = {\"prompt\":STUFF_PROMPT})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0420f8eb-cc63-4158-b456-d00a4e9c05f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 ms, sys: 0 ns, total: 12 ms\n",
      "Wall time: 557 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is pepsi', 'answer': ' I do not know.\\n', 'sources': 'N/A'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chain({\"question\": QUESTION})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347373a-a5be-473d-b64e-0f6b6dbcd0e0",
   "metadata": {},
   "source": [
    "##### This answer is way better than taking just the result from Azure Cognitive Search. So the summary is:\n",
    "- Azure Cognitive Search give us the top results\n",
    "- Azure OpenAI construct takes this results and understand them to give the best answer\n",
    "- Best of two worlds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bbc67-d75a-4044-b8ee-9d3079f891cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
